{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CaptainAmu/Reinforcement-Learning-Tutorial/blob/main/notebooks/unit3/unit3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7xBVPzoXxOg"
      },
      "source": [
        "# Unit 3: Deep Q-Learning with Atari Games üëæ using RL Baselines3 Zoo\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit4/thumbnail.jpg\" alt=\"Unit 3 Thumbnail\">\n",
        "\n",
        "In this notebook, **you'll train a Deep Q-Learning agent** playing Space Invaders using [RL Baselines3 Zoo](https://github.com/DLR-RM/rl-baselines3-zoo), a training framework based on [Stable-Baselines3](https://stable-baselines3.readthedocs.io/en/master/) that provides scripts for training, evaluating agents, tuning hyperparameters, plotting results and recording videos.\n",
        "\n",
        "We're using the [RL-Baselines-3 Zoo integration, a vanilla version of Deep Q-Learning](https://stable-baselines3.readthedocs.io/en/master/modules/dqn.html) with no extensions such as Double-DQN, Dueling-DQN, and Prioritized Experience Replay.\n",
        "\n",
        "‚¨áÔ∏è Here is an example of what **you will achieve** ‚¨áÔ∏è"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "J9S713biXntc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "603b7d5b-ad08-4dfc-c4fa-ce8bb4b6c685"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<video controls autoplay><source src=\"https://huggingface.co/ThomasSimonini/ppo-SpaceInvadersNoFrameskip-v4/resolve/main/replay.mp4\" type=\"video/mp4\"></video>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "%%html\n",
        "<video controls autoplay><source src=\"https://huggingface.co/ThomasSimonini/ppo-SpaceInvadersNoFrameskip-v4/resolve/main/replay.mp4\" type=\"video/mp4\"></video>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üéÆ Environments:\n",
        "\n",
        "- [SpacesInvadersNoFrameskip-v4](https://gymnasium.farama.org/environments/atari/space_invaders/)\n",
        "\n",
        "You can see the difference between Space Invaders versions here üëâ https://gymnasium.farama.org/environments/atari/space_invaders/#variants\n",
        "\n",
        "### üìö RL-Library:\n",
        "\n",
        "- [RL-Baselines3-Zoo](https://github.com/DLR-RM/rl-baselines3-zoo)"
      ],
      "metadata": {
        "id": "ykJiGevCMVc5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wciHGjrFYz9m"
      },
      "source": [
        "## Objectives of this notebook üèÜ\n",
        "At the end of the notebook, you will:\n",
        "- Be able to understand deeper **how RL Baselines3 Zoo works**.\n",
        "- Be able to **push your trained agent and the code to the Hub** with a nice video replay and an evaluation score üî•.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This notebook is from Deep Reinforcement Learning Course\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/deep-rl-course-illustration.jpg\" alt=\"Deep RL Course illustration\"/>"
      ],
      "metadata": {
        "id": "TsnP0rjxMn1e"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nw6fJHIAZd-J"
      },
      "source": [
        "In this free course, you will:\n",
        "\n",
        "- üìñ Study Deep Reinforcement Learning in **theory and practice**.\n",
        "- üßë‚Äçüíª Learn to **use famous Deep RL libraries** such as Stable Baselines3, RL Baselines3 Zoo, CleanRL and Sample Factory 2.0.\n",
        "- ü§ñ Train **agents in unique environments**\n",
        "\n",
        "And more check üìö the syllabus üëâ https://simoninithomas.github.io/deep-rl-course\n",
        "\n",
        "Don‚Äôt forget to **<a href=\"http://eepurl.com/ic5ZUD\">sign up to the course</a>** (we are collecting your email to be able to¬†**send you the links when each Unit is published and give you information about the challenges and updates).**\n",
        "\n",
        "\n",
        "The best way to keep in touch is to join our discord server to exchange with the community and with us üëâüèª https://discord.gg/ydHrjt3WP5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vgANIBBZg1p"
      },
      "source": [
        "## Prerequisites üèóÔ∏è\n",
        "Before diving into the notebook, you need to:\n",
        "\n",
        "üî≤ üìö **[Study Deep Q-Learning by reading Unit 3](https://huggingface.co/deep-rl-course/unit3/introduction)**  ü§ó"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're constantly trying to improve our tutorials, so **if you find some issues in this notebook**, please [open an issue on the Github Repo](https://github.com/huggingface/deep-rl-class/issues)."
      ],
      "metadata": {
        "id": "7kszpGFaRVhq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QR0jZtYreSI5"
      },
      "source": [
        "# Let's train a Deep Q-Learning agent playing Atari' Space Invaders üëæ and upload it to the Hub.\n",
        "\n",
        "We strongly recommend students **to use Google Colab for the hands-on exercises instead of running them on their personal computers**.\n",
        "\n",
        "By using Google Colab, **you can focus on learning and experimenting without worrying about the technical aspects of setting up your environments**.\n",
        "\n",
        "To validate this hands-on for the certification process, you need to push your trained model to the Hub and **get a result of >= 200**.\n",
        "\n",
        "To find your result, go to the leaderboard and find your model, **the result = mean_reward - std of reward**\n",
        "\n",
        "For more information about the certification process, check this section üëâ https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## An advice üí°\n",
        "It's better to run this colab in a copy on your Google Drive, so that **if it timeouts** you still have the saved notebook on your Google Drive and do not need to fill everything from scratch.\n",
        "\n",
        "To do that you can either do `Ctrl + S` or `File > Save a copy in Google Drive.`\n",
        "\n",
        "Also, we're going to **train it for 90 minutes with 1M timesteps**. By typing `!nvidia-smi` will tell you what GPU you're using.\n",
        "\n",
        "And if you want to train more such 10 million steps, this will take about 9 hours, potentially resulting in Colab timing out. In that case, I recommend running this on your local computer (or somewhere else). Just click on: `File>Download`."
      ],
      "metadata": {
        "id": "Nc8BnyVEc3Ys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import save\n",
        "\n",
        "def save_checkpoint(model, optimizer, timesteps, path):\n",
        "  checkpoint = dict(\n",
        "      model_state_dict = model.state_dict(),\n",
        "      optimizer_state_dict = optimizer.state_dict(),\n",
        "      timesteps = timesteps\n",
        "  )\n",
        "  save(checkpoint, path)"
      ],
      "metadata": {
        "id": "CO1vw8aEUkus"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SU3cT9Jewmae",
        "outputId": "58b4c1d0-ad8a-418f-99a9-09ff0e7450fc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Sep 15 09:44:07 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   58C    P8             12W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set the GPU üí™\n",
        "- To **accelerate the agent's training, we'll use a GPU**. To do that, go to `Runtime > Change Runtime type`\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/gpu-step1.jpg\" alt=\"GPU Step 1\">"
      ],
      "metadata": {
        "id": "PU4FVzaoM6fC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `Hardware Accelerator > GPU`\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/gpu-step2.jpg\" alt=\"GPU Step 2\">"
      ],
      "metadata": {
        "id": "KV0NyFdQM9ZG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install RL-Baselines3 Zoo and its dependencies üìö\n",
        "\n",
        "If you see `ERROR: pip's dependency resolver does not currently take into account all the packages that are installed.` **this is normal and it's not a critical error** there's a conflict of version. But the packages we need are installed."
      ],
      "metadata": {
        "id": "wS_cVefO-aYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/DLR-RM/rl-baselines3-zoo"
      ],
      "metadata": {
        "id": "S1A_E4z3awa_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23cabc31-76cf-4e68-8c36-8a5d1747bb9d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/DLR-RM/rl-baselines3-zoo\n",
            "  Cloning https://github.com/DLR-RM/rl-baselines3-zoo to /tmp/pip-req-build-vdsn8688\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/DLR-RM/rl-baselines3-zoo /tmp/pip-req-build-vdsn8688\n",
            "  Resolved https://github.com/DLR-RM/rl-baselines3-zoo to commit ab4aadb57c6c42abcf1016318c2bebe35c4c1270\n",
            "  Running command git submodule update --init --recursive -q\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sb3_contrib<3.0,>=2.7.0 (from rl_zoo3==2.7.0)\n",
            "  Downloading sb3_contrib-2.7.0-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: gymnasium<1.3.0,>=0.29.1 in /usr/local/lib/python3.12/dist-packages (from rl_zoo3==2.7.0) (1.2.0)\n",
            "Collecting huggingface_sb3<4.0,>=3.0 (from rl_zoo3==2.7.0)\n",
            "  Downloading huggingface_sb3-3.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from rl_zoo3==2.7.0) (4.67.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from rl_zoo3==2.7.0) (13.9.4)\n",
            "Collecting optuna>=3.0 (from rl_zoo3==2.7.0)\n",
            "  Downloading optuna-4.5.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from rl_zoo3==2.7.0) (6.0.2)\n",
            "Collecting pytablewriter~=1.2 (from rl_zoo3==2.7.0)\n",
            "  Downloading pytablewriter-1.2.1-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting shimmy~=2.0 (from rl_zoo3==2.7.0)\n",
            "  Downloading Shimmy-2.0.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium<1.3.0,>=0.29.1->rl_zoo3==2.7.0) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium<1.3.0,>=0.29.1->rl_zoo3==2.7.0) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium<1.3.0,>=0.29.1->rl_zoo3==2.7.0) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium<1.3.0,>=0.29.1->rl_zoo3==2.7.0) (0.0.4)\n",
            "Requirement already satisfied: huggingface-hub~=0.8 in /usr/local/lib/python3.12/dist-packages (from huggingface_sb3<4.0,>=3.0->rl_zoo3==2.7.0) (0.34.4)\n",
            "Requirement already satisfied: wasabi in /usr/local/lib/python3.12/dist-packages (from huggingface_sb3<4.0,>=3.0->rl_zoo3==2.7.0) (1.1.3)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna>=3.0->rl_zoo3==2.7.0) (1.16.5)\n",
            "Collecting colorlog (from optuna>=3.0->rl_zoo3==2.7.0)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna>=3.0->rl_zoo3==2.7.0) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna>=3.0->rl_zoo3==2.7.0) (2.0.43)\n",
            "Requirement already satisfied: setuptools>=38.3.0 in /usr/local/lib/python3.12/dist-packages (from pytablewriter~=1.2->rl_zoo3==2.7.0) (75.2.0)\n",
            "Collecting DataProperty<2,>=1.1.0 (from pytablewriter~=1.2->rl_zoo3==2.7.0)\n",
            "  Downloading DataProperty-1.1.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting mbstrdecoder<2,>=1.0.0 (from pytablewriter~=1.2->rl_zoo3==2.7.0)\n",
            "  Downloading mbstrdecoder-1.1.4-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting pathvalidate<4,>=2.3.0 (from pytablewriter~=1.2->rl_zoo3==2.7.0)\n",
            "  Downloading pathvalidate-3.3.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting tabledata<2,>=1.3.1 (from pytablewriter~=1.2->rl_zoo3==2.7.0)\n",
            "  Downloading tabledata-1.3.4-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting tcolorpy<1,>=0.0.5 (from pytablewriter~=1.2->rl_zoo3==2.7.0)\n",
            "  Downloading tcolorpy-0.1.7-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting typepy<2,>=1.3.2 (from typepy[datetime]<2,>=1.3.2->pytablewriter~=1.2->rl_zoo3==2.7.0)\n",
            "  Downloading typepy-1.3.4-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting stable_baselines3<3.0,>=2.7.0 (from sb3_contrib<3.0,>=2.7.0->rl_zoo3==2.7.0)\n",
            "  Downloading stable_baselines3-2.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->rl_zoo3==2.7.0) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->rl_zoo3==2.7.0) (2.19.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna>=3.0->rl_zoo3==2.7.0) (1.3.10)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub~=0.8->huggingface_sb3<4.0,>=3.0->rl_zoo3==2.7.0) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub~=0.8->huggingface_sb3<4.0,>=3.0->rl_zoo3==2.7.0) (2025.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub~=0.8->huggingface_sb3<4.0,>=3.0->rl_zoo3==2.7.0) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub~=0.8->huggingface_sb3<4.0,>=3.0->rl_zoo3==2.7.0) (1.1.9)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->rl_zoo3==2.7.0) (0.1.2)\n",
            "Requirement already satisfied: chardet<6,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter~=1.2->rl_zoo3==2.7.0) (5.2.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna>=3.0->rl_zoo3==2.7.0) (3.2.4)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.12/dist-packages (from stable_baselines3<3.0,>=2.7.0->sb3_contrib<3.0,>=2.7.0->rl_zoo3==2.7.0) (2.8.0+cu126)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from stable_baselines3<3.0,>=2.7.0->sb3_contrib<3.0,>=2.7.0->rl_zoo3==2.7.0) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from stable_baselines3<3.0,>=2.7.0->sb3_contrib<3.0,>=2.7.0->rl_zoo3==2.7.0) (3.10.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter~=1.2->rl_zoo3==2.7.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2018.9 in /usr/local/lib/python3.12/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter~=1.2->rl_zoo3==2.7.0) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.8.0->typepy[datetime]<2,>=1.3.2->pytablewriter~=1.2->rl_zoo3==2.7.0) (1.17.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib<3.0,>=2.7.0->rl_zoo3==2.7.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib<3.0,>=2.7.0->rl_zoo3==2.7.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib<3.0,>=2.7.0->rl_zoo3==2.7.0) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib<3.0,>=2.7.0->rl_zoo3==2.7.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib<3.0,>=2.7.0->rl_zoo3==2.7.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib<3.0,>=2.7.0->rl_zoo3==2.7.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib<3.0,>=2.7.0->rl_zoo3==2.7.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib<3.0,>=2.7.0->rl_zoo3==2.7.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib<3.0,>=2.7.0->rl_zoo3==2.7.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib<3.0,>=2.7.0->rl_zoo3==2.7.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib<3.0,>=2.7.0->rl_zoo3==2.7.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib<3.0,>=2.7.0->rl_zoo3==2.7.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib<3.0,>=2.7.0->rl_zoo3==2.7.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib<3.0,>=2.7.0->rl_zoo3==2.7.0) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib<3.0,>=2.7.0->rl_zoo3==2.7.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib<3.0,>=2.7.0->rl_zoo3==2.7.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib<3.0,>=2.7.0->rl_zoo3==2.7.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib<3.0,>=2.7.0->rl_zoo3==2.7.0) (3.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna>=3.0->rl_zoo3==2.7.0) (3.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.7.0->sb3_contrib<3.0,>=2.7.0->rl_zoo3==2.7.0) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.7.0->sb3_contrib<3.0,>=2.7.0->rl_zoo3==2.7.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.7.0->sb3_contrib<3.0,>=2.7.0->rl_zoo3==2.7.0) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.7.0->sb3_contrib<3.0,>=2.7.0->rl_zoo3==2.7.0) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.7.0->sb3_contrib<3.0,>=2.7.0->rl_zoo3==2.7.0) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.7.0->sb3_contrib<3.0,>=2.7.0->rl_zoo3==2.7.0) (3.2.3)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->stable_baselines3<3.0,>=2.7.0->sb3_contrib<3.0,>=2.7.0->rl_zoo3==2.7.0) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub~=0.8->huggingface_sb3<4.0,>=3.0->rl_zoo3==2.7.0) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub~=0.8->huggingface_sb3<4.0,>=3.0->rl_zoo3==2.7.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub~=0.8->huggingface_sb3<4.0,>=3.0->rl_zoo3==2.7.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub~=0.8->huggingface_sb3<4.0,>=3.0->rl_zoo3==2.7.0) (2025.8.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3.0,>=2.3->stable_baselines3<3.0,>=2.7.0->sb3_contrib<3.0,>=2.7.0->rl_zoo3==2.7.0) (1.3.0)\n",
            "Downloading huggingface_sb3-3.0-py3-none-any.whl (9.7 kB)\n",
            "Downloading optuna-4.5.0-py3-none-any.whl (400 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytablewriter-1.2.1-py3-none-any.whl (91 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m91.1/91.1 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sb3_contrib-2.7.0-py3-none-any.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Shimmy-2.0.0-py3-none-any.whl (30 kB)\n",
            "Downloading DataProperty-1.1.0-py3-none-any.whl (27 kB)\n",
            "Downloading mbstrdecoder-1.1.4-py3-none-any.whl (7.9 kB)\n",
            "Downloading pathvalidate-3.3.1-py3-none-any.whl (24 kB)\n",
            "Downloading stable_baselines3-2.7.0-py3-none-any.whl (187 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m187.2/187.2 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tabledata-1.3.4-py3-none-any.whl (11 kB)\n",
            "Downloading tcolorpy-0.1.7-py3-none-any.whl (8.1 kB)\n",
            "Downloading typepy-1.3.4-py3-none-any.whl (31 kB)\n",
            "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Building wheels for collected packages: rl_zoo3\n",
            "  Building wheel for rl_zoo3 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rl_zoo3: filename=rl_zoo3-2.7.0-py3-none-any.whl size=78020 sha256=ca4e0cf517c26744208a0ccb56fe4c6adad509da00bea1932c7cfb7b64a48801\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-n7f6og8h/wheels/cd/09/5b/8130538724a187021e02afe53ce7a1269c516a78a487a1ba15\n",
            "Successfully built rl_zoo3\n",
            "Installing collected packages: tcolorpy, pathvalidate, mbstrdecoder, colorlog, typepy, shimmy, optuna, huggingface_sb3, stable_baselines3, DataProperty, tabledata, sb3_contrib, pytablewriter, rl_zoo3\n",
            "Successfully installed DataProperty-1.1.0 colorlog-6.9.0 huggingface_sb3-3.0 mbstrdecoder-1.1.4 optuna-4.5.0 pathvalidate-3.3.1 pytablewriter-1.2.1 rl_zoo3-2.7.0 sb3_contrib-2.7.0 shimmy-2.0.0 stable_baselines3-2.7.0 tabledata-1.3.4 tcolorpy-0.1.7 typepy-1.3.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install swig cmake ffmpeg"
      ],
      "metadata": {
        "id": "8_MllY6Om1eI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d31aeb34-6d67-4f15-d0eb-d27623b49ca3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "cmake is already the newest version (3.22.1-1ubuntu1.22.04.2).\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "The following additional packages will be installed:\n",
            "  swig4.0\n",
            "Suggested packages:\n",
            "  swig-doc swig-examples swig4.0-examples swig4.0-doc\n",
            "The following NEW packages will be installed:\n",
            "  swig swig4.0\n",
            "0 upgraded, 2 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 1,116 kB of archives.\n",
            "After this operation, 5,542 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig4.0 amd64 4.0.2-1ubuntu1 [1,110 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig all 4.0.2-1ubuntu1 [5,632 B]\n",
            "Fetched 1,116 kB in 1s (1,306 kB/s)\n",
            "Selecting previously unselected package swig4.0.\n",
            "(Reading database ... 126374 files and directories currently installed.)\n",
            "Preparing to unpack .../swig4.0_4.0.2-1ubuntu1_amd64.deb ...\n",
            "Unpacking swig4.0 (4.0.2-1ubuntu1) ...\n",
            "Selecting previously unselected package swig.\n",
            "Preparing to unpack .../swig_4.0.2-1ubuntu1_all.deb ...\n",
            "Unpacking swig (4.0.2-1ubuntu1) ...\n",
            "Setting up swig4.0 (4.0.2-1ubuntu1) ...\n",
            "Setting up swig (4.0.2-1ubuntu1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4S9mJiKg6SqC"
      },
      "source": [
        "To be able to use Atari games in Gymnasium we need to install atari package. And accept-rom-license to download the rom files (games files)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gymnasium[atari]\n",
        "!pip install gymnasium[accept-rom-license]"
      ],
      "metadata": {
        "id": "NsRP-lX1_2fC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a78852c0-a120-4737-97df-4187ac7ebfa9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium[atari] in /usr/local/lib/python3.12/dist-packages (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[atari]) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[atari]) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[atari]) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium[atari]) (0.0.4)\n",
            "Requirement already satisfied: ale_py>=0.9 in /usr/local/lib/python3.12/dist-packages (from gymnasium[atari]) (0.11.2)\n",
            "Requirement already satisfied: gymnasium[accept-rom-license] in /usr/local/lib/python3.12/dist-packages (1.2.0)\n",
            "\u001b[33mWARNING: gymnasium 1.2.0 does not provide the extra 'accept-rom-license'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[accept-rom-license]) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[accept-rom-license]) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[accept-rom-license]) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium[accept-rom-license]) (0.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a virtual display üîΩ\n",
        "\n",
        "During the notebook, we'll need to generate a replay video. To do so, with colab, **we need to have a virtual screen to be able to render the environment** (and thus record the frames).\n",
        "\n",
        "Hence the following cell will install the librairies and create and run a virtual screen üñ•"
      ],
      "metadata": {
        "id": "bTpYcVZVMzUI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jV6wjQ7Be7p5"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!apt install python-opengl\n",
        "!apt install xvfb\n",
        "!pip3 install pyvirtualdisplay"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Virtual display\n",
        "from pyvirtualdisplay import Display\n",
        "\n",
        "virtual_display = Display(visible=0, size=(1400, 900))\n",
        "virtual_display.start()"
      ],
      "metadata": {
        "id": "BE5JWP5rQIKf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e3525e0-b2d2-43da-bde1-8c70104f9200"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7b24e74fa1e0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iPgzluo9z-u"
      },
      "source": [
        "## Train our Deep Q-Learning Agent to Play Space Invaders üëæ\n",
        "\n",
        "To train an agent with RL-Baselines3-Zoo, we just need to do two things:\n",
        "\n",
        "1. Create a hyperparameter config file that will contain our training hyperparameters called `dqn.yml`. **Â∞±Êää‰∏ãÈù¢ËøôÂù®‰∏úË•øÊîæËøõ```.yml``` ,ÁÑ∂ÂêéÊîæÂú®contentÊâÄÂú®ÁõÆÂΩïÈáåÂ∞±ÂèØ‰ª•„ÄÇ**\n",
        "\n",
        "This is a template example:\n",
        "\n",
        "```\n",
        "SpaceInvadersNoFrameskip-v4:\n",
        "  env_wrapper:\n",
        "    - stable_baselines3.common.atari_wrappers.AtariWrapper\n",
        "  frame_stack: 4\n",
        "  policy: 'CnnPolicy'\n",
        "  n_timesteps: !!float 1e6\n",
        "  buffer_size: 100000\n",
        "  learning_rate: !!float 1e-4\n",
        "  batch_size: 32\n",
        "  learning_starts: 100000\n",
        "  target_update_interval: 1000\n",
        "  train_freq: 4\n",
        "  gradient_steps: 1\n",
        "  exploration_fraction: 0.1\n",
        "  exploration_final_eps: 0.01\n",
        "  # If True, you need to deactivate handle_timeout_termination\n",
        "  # in the replay_buffer_kwargs\n",
        "  optimize_memory_usage: False\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VjblFSVDQOj"
      },
      "source": [
        "Here we see that:\n",
        "- We use the `Atari Wrapper` that preprocess the input (Frame reduction ,grayscale, stack 4 frames)\n",
        "- We use `CnnPolicy`, since we use Convolutional layers to process the frames\n",
        "- We train it for 10 million `n_timesteps`\n",
        "- Memory (Experience Replay) size is 100000, aka the amount of experience steps you saved to train again your agent with.\n",
        "\n",
        "üí° My advice is to **reduce the training timesteps to 1M,** which will take about 90 minutes on a P100. `!nvidia-smi` will tell you what GPU you're using. At 10 million steps, this will take about 9 hours, which could likely result in Colab timing out. I recommend running this on your local computer (or somewhere else). Just click on: `File>Download`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKvuOkmkyEZH",
        "outputId": "9805ff81-ac92-4b63-b7e6-f207a07908b5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Sep 15 09:50:22 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P8             11W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qTkbWrkECOJ"
      },
      "source": [
        "In terms of hyperparameters optimization, my advice is to focus on these 3 hyperparameters:\n",
        "- `learning_rate`\n",
        "- `buffer_size (Experience Memory size)`\n",
        "- `batch_size`\n",
        "\n",
        "As a good practice, you need to **check the documentation to understand what each hyperparameters does**: https://stable-baselines3.readthedocs.io/en/master/modules/dqn.html#parameters\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hn8bRTHvERRL"
      },
      "source": [
        "2. We start the training and save the models on `logs` folder üìÅ\n",
        "\n",
        "- Define the algorithm after `--algo`, where we save the model after `-f` and where the hyperparameter config is after `-c`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Xr1TVW4xfbz3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "195e939f-dd88-4e32-9825-acfc5e870dbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mÊµÅÂºèËæìÂá∫ÂÜÖÂÆπË¢´Êà™Êñ≠ÔºåÂè™ËÉΩÊòæÁ§∫ÊúÄÂêé 5000 Ë°åÂÜÖÂÆπ„ÄÇ\u001b[0m\n",
            "| time/               |          |\n",
            "|    episodes         | 2616     |\n",
            "|    fps              | 274      |\n",
            "|    time_elapsed     | 1964     |\n",
            "|    total_timesteps  | 539700   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0747   |\n",
            "|    n_updates        | 109924   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 2.98e+03 |\n",
            "|    ep_rew_mean      | 366      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2620     |\n",
            "|    fps              | 274      |\n",
            "|    time_elapsed     | 1965     |\n",
            "|    total_timesteps  | 540160   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0207   |\n",
            "|    n_updates        | 110039   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3e+03    |\n",
            "|    ep_rew_mean      | 368      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2624     |\n",
            "|    fps              | 274      |\n",
            "|    time_elapsed     | 1970     |\n",
            "|    total_timesteps  | 541338   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0295   |\n",
            "|    n_updates        | 110334   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.02e+03 |\n",
            "|    ep_rew_mean      | 370      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2628     |\n",
            "|    fps              | 274      |\n",
            "|    time_elapsed     | 1975     |\n",
            "|    total_timesteps  | 542736   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0274   |\n",
            "|    n_updates        | 110683   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.03e+03 |\n",
            "|    ep_rew_mean      | 371      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2632     |\n",
            "|    fps              | 274      |\n",
            "|    time_elapsed     | 1978     |\n",
            "|    total_timesteps  | 543449   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0309   |\n",
            "|    n_updates        | 110862   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.02e+03 |\n",
            "|    ep_rew_mean      | 370      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2636     |\n",
            "|    fps              | 274      |\n",
            "|    time_elapsed     | 1980     |\n",
            "|    total_timesteps  | 544201   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0221   |\n",
            "|    n_updates        | 111050   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.02e+03 |\n",
            "|    ep_rew_mean      | 368      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2640     |\n",
            "|    fps              | 274      |\n",
            "|    time_elapsed     | 1983     |\n",
            "|    total_timesteps  | 544955   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0194   |\n",
            "|    n_updates        | 111238   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.01e+03 |\n",
            "|    ep_rew_mean      | 366      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2644     |\n",
            "|    fps              | 274      |\n",
            "|    time_elapsed     | 1987     |\n",
            "|    total_timesteps  | 545907   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0236   |\n",
            "|    n_updates        | 111476   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.01e+03 |\n",
            "|    ep_rew_mean      | 366      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2648     |\n",
            "|    fps              | 274      |\n",
            "|    time_elapsed     | 1990     |\n",
            "|    total_timesteps  | 546544   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0353   |\n",
            "|    n_updates        | 111635   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.01e+03 |\n",
            "|    ep_rew_mean      | 365      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2652     |\n",
            "|    fps              | 274      |\n",
            "|    time_elapsed     | 1993     |\n",
            "|    total_timesteps  | 547534   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0317   |\n",
            "|    n_updates        | 111883   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3e+03    |\n",
            "|    ep_rew_mean      | 361      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2656     |\n",
            "|    fps              | 274      |\n",
            "|    time_elapsed     | 1997     |\n",
            "|    total_timesteps  | 548504   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.027    |\n",
            "|    n_updates        | 112125   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.01e+03 |\n",
            "|    ep_rew_mean      | 365      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2660     |\n",
            "|    fps              | 274      |\n",
            "|    time_elapsed     | 2001     |\n",
            "|    total_timesteps  | 549490   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0198   |\n",
            "|    n_updates        | 112372   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=550000, episode_reward=395.00 +/- 77.46\n",
            "Episode length: 2391.80 +/- 343.88\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 2.39e+03 |\n",
            "|    mean_reward      | 395      |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 550000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0197   |\n",
            "|    n_updates        | 112499   |\n",
            "----------------------------------\n",
            "New best mean reward!\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.02e+03 |\n",
            "|    ep_rew_mean      | 365      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2664     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 2011     |\n",
            "|    total_timesteps  | 550455   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0295   |\n",
            "|    n_updates        | 112613   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.01e+03 |\n",
            "|    ep_rew_mean      | 364      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2668     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 2015     |\n",
            "|    total_timesteps  | 551585   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0359   |\n",
            "|    n_updates        | 112896   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3e+03    |\n",
            "|    ep_rew_mean      | 362      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2672     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 2018     |\n",
            "|    total_timesteps  | 552155   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0298   |\n",
            "|    n_updates        | 113038   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.02e+03 |\n",
            "|    ep_rew_mean      | 366      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2676     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 2023     |\n",
            "|    total_timesteps  | 553492   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0169   |\n",
            "|    n_updates        | 113372   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.04e+03 |\n",
            "|    ep_rew_mean      | 370      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2680     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 2027     |\n",
            "|    total_timesteps  | 554561   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.03     |\n",
            "|    n_updates        | 113640   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.05e+03 |\n",
            "|    ep_rew_mean      | 373      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2684     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 2032     |\n",
            "|    total_timesteps  | 555752   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0435   |\n",
            "|    n_updates        | 113937   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.05e+03 |\n",
            "|    ep_rew_mean      | 375      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2688     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 2036     |\n",
            "|    total_timesteps  | 556905   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0195   |\n",
            "|    n_updates        | 114226   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.06e+03 |\n",
            "|    ep_rew_mean      | 379      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2692     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 2042     |\n",
            "|    total_timesteps  | 558496   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0141   |\n",
            "|    n_updates        | 114623   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.09e+03 |\n",
            "|    ep_rew_mean      | 382      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2696     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 2047     |\n",
            "|    total_timesteps  | 559826   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0499   |\n",
            "|    n_updates        | 114956   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.1e+03  |\n",
            "|    ep_rew_mean      | 383      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2700     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 2054     |\n",
            "|    total_timesteps  | 561686   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0467   |\n",
            "|    n_updates        | 115421   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.12e+03 |\n",
            "|    ep_rew_mean      | 389      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2704     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 2059     |\n",
            "|    total_timesteps  | 563154   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0157   |\n",
            "|    n_updates        | 115788   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.14e+03 |\n",
            "|    ep_rew_mean      | 392      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2708     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 2064     |\n",
            "|    total_timesteps  | 564458   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.015    |\n",
            "|    n_updates        | 116114   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.14e+03 |\n",
            "|    ep_rew_mean      | 391      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2712     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 2068     |\n",
            "|    total_timesteps  | 565417   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0538   |\n",
            "|    n_updates        | 116354   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.13e+03 |\n",
            "|    ep_rew_mean      | 391      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2716     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 2074     |\n",
            "|    total_timesteps  | 567061   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0357   |\n",
            "|    n_updates        | 116765   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.1e+03  |\n",
            "|    ep_rew_mean      | 391      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2720     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 2077     |\n",
            "|    total_timesteps  | 567890   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0117   |\n",
            "|    n_updates        | 116972   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.11e+03 |\n",
            "|    ep_rew_mean      | 394      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2724     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 2082     |\n",
            "|    total_timesteps  | 569117   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0252   |\n",
            "|    n_updates        | 117279   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.12e+03 |\n",
            "|    ep_rew_mean      | 398      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2728     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 2084     |\n",
            "|    total_timesteps  | 569757   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.022    |\n",
            "|    n_updates        | 117439   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.09e+03 |\n",
            "|    ep_rew_mean      | 395      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2732     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 2089     |\n",
            "|    total_timesteps  | 571166   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0105   |\n",
            "|    n_updates        | 117791   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.09e+03 |\n",
            "|    ep_rew_mean      | 399      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2736     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 2093     |\n",
            "|    total_timesteps  | 572090   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.027    |\n",
            "|    n_updates        | 118022   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.08e+03 |\n",
            "|    ep_rew_mean      | 399      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2740     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 2097     |\n",
            "|    total_timesteps  | 573161   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0142   |\n",
            "|    n_updates        | 118290   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.09e+03 |\n",
            "|    ep_rew_mean      | 404      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2744     |\n",
            "|    fps              | 273      |\n",
            "|    time_elapsed     | 2101     |\n",
            "|    total_timesteps  | 574280   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0138   |\n",
            "|    n_updates        | 118569   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=575000, episode_reward=387.00 +/- 240.24\n",
            "Episode length: 2993.40 +/- 1079.86\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 2.99e+03 |\n",
            "|    mean_reward      | 387      |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 575000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0366   |\n",
            "|    n_updates        | 118749   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.11e+03 |\n",
            "|    ep_rew_mean      | 410      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2748     |\n",
            "|    fps              | 272      |\n",
            "|    time_elapsed     | 2114     |\n",
            "|    total_timesteps  | 575683   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0176   |\n",
            "|    n_updates        | 118920   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.11e+03 |\n",
            "|    ep_rew_mean      | 408      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2752     |\n",
            "|    fps              | 272      |\n",
            "|    time_elapsed     | 2116     |\n",
            "|    total_timesteps  | 576225   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.019    |\n",
            "|    n_updates        | 119056   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.11e+03 |\n",
            "|    ep_rew_mean      | 409      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2756     |\n",
            "|    fps              | 272      |\n",
            "|    time_elapsed     | 2120     |\n",
            "|    total_timesteps  | 577147   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0372   |\n",
            "|    n_updates        | 119286   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.11e+03 |\n",
            "|    ep_rew_mean      | 411      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2760     |\n",
            "|    fps              | 272      |\n",
            "|    time_elapsed     | 2124     |\n",
            "|    total_timesteps  | 578099   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0247   |\n",
            "|    n_updates        | 119524   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.1e+03  |\n",
            "|    ep_rew_mean      | 408      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2764     |\n",
            "|    fps              | 272      |\n",
            "|    time_elapsed     | 2129     |\n",
            "|    total_timesteps  | 579577   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0229   |\n",
            "|    n_updates        | 119894   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.1e+03  |\n",
            "|    ep_rew_mean      | 411      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2768     |\n",
            "|    fps              | 272      |\n",
            "|    time_elapsed     | 2133     |\n",
            "|    total_timesteps  | 580500   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0272   |\n",
            "|    n_updates        | 120124   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.11e+03 |\n",
            "|    ep_rew_mean      | 413      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2772     |\n",
            "|    fps              | 272      |\n",
            "|    time_elapsed     | 2138     |\n",
            "|    total_timesteps  | 581972   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0182   |\n",
            "|    n_updates        | 120492   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.11e+03 |\n",
            "|    ep_rew_mean      | 415      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2776     |\n",
            "|    fps              | 272      |\n",
            "|    time_elapsed     | 2143     |\n",
            "|    total_timesteps  | 583216   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0243   |\n",
            "|    n_updates        | 120803   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.11e+03 |\n",
            "|    ep_rew_mean      | 415      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2780     |\n",
            "|    fps              | 272      |\n",
            "|    time_elapsed     | 2146     |\n",
            "|    total_timesteps  | 584133   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0377   |\n",
            "|    n_updates        | 121033   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.1e+03  |\n",
            "|    ep_rew_mean      | 412      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2784     |\n",
            "|    fps              | 272      |\n",
            "|    time_elapsed     | 2150     |\n",
            "|    total_timesteps  | 585188   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0177   |\n",
            "|    n_updates        | 121296   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.11e+03 |\n",
            "|    ep_rew_mean      | 416      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2788     |\n",
            "|    fps              | 272      |\n",
            "|    time_elapsed     | 2155     |\n",
            "|    total_timesteps  | 586401   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0146   |\n",
            "|    n_updates        | 121600   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.1e+03  |\n",
            "|    ep_rew_mean      | 413      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2792     |\n",
            "|    fps              | 272      |\n",
            "|    time_elapsed     | 2158     |\n",
            "|    total_timesteps  | 587167   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0428   |\n",
            "|    n_updates        | 121791   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.07e+03 |\n",
            "|    ep_rew_mean      | 409      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2796     |\n",
            "|    fps              | 272      |\n",
            "|    time_elapsed     | 2163     |\n",
            "|    total_timesteps  | 588681   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.041    |\n",
            "|    n_updates        | 122170   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.07e+03 |\n",
            "|    ep_rew_mean      | 411      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2800     |\n",
            "|    fps              | 271      |\n",
            "|    time_elapsed     | 2169     |\n",
            "|    total_timesteps  | 589968   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0198   |\n",
            "|    n_updates        | 122491   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.06e+03 |\n",
            "|    ep_rew_mean      | 411      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2804     |\n",
            "|    fps              | 272      |\n",
            "|    time_elapsed     | 2172     |\n",
            "|    total_timesteps  | 590977   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0306   |\n",
            "|    n_updates        | 122744   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.05e+03 |\n",
            "|    ep_rew_mean      | 412      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2808     |\n",
            "|    fps              | 272      |\n",
            "|    time_elapsed     | 2175     |\n",
            "|    total_timesteps  | 591712   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0448   |\n",
            "|    n_updates        | 122927   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.05e+03 |\n",
            "|    ep_rew_mean      | 411      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2812     |\n",
            "|    fps              | 272      |\n",
            "|    time_elapsed     | 2177     |\n",
            "|    total_timesteps  | 592314   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0174   |\n",
            "|    n_updates        | 123078   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.04e+03 |\n",
            "|    ep_rew_mean      | 410      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2816     |\n",
            "|    fps              | 271      |\n",
            "|    time_elapsed     | 2181     |\n",
            "|    total_timesteps  | 593125   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0543   |\n",
            "|    n_updates        | 123281   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.05e+03 |\n",
            "|    ep_rew_mean      | 409      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2820     |\n",
            "|    fps              | 271      |\n",
            "|    time_elapsed     | 2183     |\n",
            "|    total_timesteps  | 593786   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0165   |\n",
            "|    n_updates        | 123446   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.07e+03 |\n",
            "|    ep_rew_mean      | 410      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2824     |\n",
            "|    fps              | 271      |\n",
            "|    time_elapsed     | 2186     |\n",
            "|    total_timesteps  | 594774   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0106   |\n",
            "|    n_updates        | 123693   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.06e+03 |\n",
            "|    ep_rew_mean      | 412      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2828     |\n",
            "|    fps              | 271      |\n",
            "|    time_elapsed     | 2193     |\n",
            "|    total_timesteps  | 596335   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0438   |\n",
            "|    n_updates        | 124083   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.08e+03 |\n",
            "|    ep_rew_mean      | 413      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2832     |\n",
            "|    fps              | 271      |\n",
            "|    time_elapsed     | 2197     |\n",
            "|    total_timesteps  | 597421   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0323   |\n",
            "|    n_updates        | 124355   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.07e+03 |\n",
            "|    ep_rew_mean      | 414      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2836     |\n",
            "|    fps              | 271      |\n",
            "|    time_elapsed     | 2201     |\n",
            "|    total_timesteps  | 598611   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0154   |\n",
            "|    n_updates        | 124652   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.07e+03 |\n",
            "|    ep_rew_mean      | 413      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2840     |\n",
            "|    fps              | 271      |\n",
            "|    time_elapsed     | 2204     |\n",
            "|    total_timesteps  | 599294   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0435   |\n",
            "|    n_updates        | 124823   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=600000, episode_reward=377.00 +/- 68.96\n",
            "Episode length: 2909.80 +/- 704.61\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 2.91e+03 |\n",
            "|    mean_reward      | 377      |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 600000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0151   |\n",
            "|    n_updates        | 124999   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.07e+03 |\n",
            "|    ep_rew_mean      | 413      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2844     |\n",
            "|    fps              | 270      |\n",
            "|    time_elapsed     | 2215     |\n",
            "|    total_timesteps  | 600335   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0255   |\n",
            "|    n_updates        | 125083   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.07e+03 |\n",
            "|    ep_rew_mean      | 413      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2848     |\n",
            "|    fps              | 270      |\n",
            "|    time_elapsed     | 2220     |\n",
            "|    total_timesteps  | 601571   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0133   |\n",
            "|    n_updates        | 125392   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.09e+03 |\n",
            "|    ep_rew_mean      | 417      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2852     |\n",
            "|    fps              | 270      |\n",
            "|    time_elapsed     | 2226     |\n",
            "|    total_timesteps  | 603407   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0346   |\n",
            "|    n_updates        | 125851   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.1e+03  |\n",
            "|    ep_rew_mean      | 417      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2856     |\n",
            "|    fps              | 270      |\n",
            "|    time_elapsed     | 2231     |\n",
            "|    total_timesteps  | 604516   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0329   |\n",
            "|    n_updates        | 126128   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.1e+03  |\n",
            "|    ep_rew_mean      | 418      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2860     |\n",
            "|    fps              | 270      |\n",
            "|    time_elapsed     | 2236     |\n",
            "|    total_timesteps  | 605964   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.016    |\n",
            "|    n_updates        | 126490   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.13e+03 |\n",
            "|    ep_rew_mean      | 421      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2864     |\n",
            "|    fps              | 270      |\n",
            "|    time_elapsed     | 2241     |\n",
            "|    total_timesteps  | 607169   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.025    |\n",
            "|    n_updates        | 126792   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.13e+03 |\n",
            "|    ep_rew_mean      | 422      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2868     |\n",
            "|    fps              | 270      |\n",
            "|    time_elapsed     | 2243     |\n",
            "|    total_timesteps  | 607798   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0426   |\n",
            "|    n_updates        | 126949   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.14e+03 |\n",
            "|    ep_rew_mean      | 422      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2872     |\n",
            "|    fps              | 270      |\n",
            "|    time_elapsed     | 2247     |\n",
            "|    total_timesteps  | 608920   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0836   |\n",
            "|    n_updates        | 127229   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.13e+03 |\n",
            "|    ep_rew_mean      | 420      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2876     |\n",
            "|    fps              | 270      |\n",
            "|    time_elapsed     | 2250     |\n",
            "|    total_timesteps  | 609851   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0114   |\n",
            "|    n_updates        | 127462   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.11e+03 |\n",
            "|    ep_rew_mean      | 418      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2880     |\n",
            "|    fps              | 270      |\n",
            "|    time_elapsed     | 2254     |\n",
            "|    total_timesteps  | 610839   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0165   |\n",
            "|    n_updates        | 127709   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.13e+03 |\n",
            "|    ep_rew_mean      | 420      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2884     |\n",
            "|    fps              | 270      |\n",
            "|    time_elapsed     | 2258     |\n",
            "|    total_timesteps  | 611839   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0491   |\n",
            "|    n_updates        | 127959   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.12e+03 |\n",
            "|    ep_rew_mean      | 418      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2888     |\n",
            "|    fps              | 270      |\n",
            "|    time_elapsed     | 2262     |\n",
            "|    total_timesteps  | 613015   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0379   |\n",
            "|    n_updates        | 128253   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.13e+03 |\n",
            "|    ep_rew_mean      | 421      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2892     |\n",
            "|    fps              | 270      |\n",
            "|    time_elapsed     | 2270     |\n",
            "|    total_timesteps  | 614853   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0191   |\n",
            "|    n_updates        | 128713   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.12e+03 |\n",
            "|    ep_rew_mean      | 420      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2896     |\n",
            "|    fps              | 270      |\n",
            "|    time_elapsed     | 2275     |\n",
            "|    total_timesteps  | 616343   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0167   |\n",
            "|    n_updates        | 129085   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.14e+03 |\n",
            "|    ep_rew_mean      | 425      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2900     |\n",
            "|    fps              | 270      |\n",
            "|    time_elapsed     | 2280     |\n",
            "|    total_timesteps  | 617389   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0153   |\n",
            "|    n_updates        | 129347   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.16e+03 |\n",
            "|    ep_rew_mean      | 428      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2904     |\n",
            "|    fps              | 270      |\n",
            "|    time_elapsed     | 2283     |\n",
            "|    total_timesteps  | 618375   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.022    |\n",
            "|    n_updates        | 129593   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.14e+03 |\n",
            "|    ep_rew_mean      | 426      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2908     |\n",
            "|    fps              | 270      |\n",
            "|    time_elapsed     | 2288     |\n",
            "|    total_timesteps  | 619801   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0468   |\n",
            "|    n_updates        | 129950   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.15e+03 |\n",
            "|    ep_rew_mean      | 428      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2912     |\n",
            "|    fps              | 270      |\n",
            "|    time_elapsed     | 2293     |\n",
            "|    total_timesteps  | 620923   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0243   |\n",
            "|    n_updates        | 130230   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.17e+03 |\n",
            "|    ep_rew_mean      | 432      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2916     |\n",
            "|    fps              | 270      |\n",
            "|    time_elapsed     | 2297     |\n",
            "|    total_timesteps  | 622073   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0265   |\n",
            "|    n_updates        | 130518   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.18e+03 |\n",
            "|    ep_rew_mean      | 432      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2920     |\n",
            "|    fps              | 270      |\n",
            "|    time_elapsed     | 2300     |\n",
            "|    total_timesteps  | 622871   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0109   |\n",
            "|    n_updates        | 130717   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.19e+03 |\n",
            "|    ep_rew_mean      | 438      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2924     |\n",
            "|    fps              | 270      |\n",
            "|    time_elapsed     | 2306     |\n",
            "|    total_timesteps  | 624448   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0162   |\n",
            "|    n_updates        | 131111   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=625000, episode_reward=467.00 +/- 87.56\n",
            "Episode length: 3195.60 +/- 570.39\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 3.2e+03  |\n",
            "|    mean_reward      | 467      |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 625000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0204   |\n",
            "|    n_updates        | 131249   |\n",
            "----------------------------------\n",
            "New best mean reward!\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.21e+03 |\n",
            "|    ep_rew_mean      | 442      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2928     |\n",
            "|    fps              | 269      |\n",
            "|    time_elapsed     | 2319     |\n",
            "|    total_timesteps  | 625458   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0242   |\n",
            "|    n_updates        | 131364   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.24e+03 |\n",
            "|    ep_rew_mean      | 446      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2932     |\n",
            "|    fps              | 269      |\n",
            "|    time_elapsed     | 2324     |\n",
            "|    total_timesteps  | 627008   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0301   |\n",
            "|    n_updates        | 131751   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.24e+03 |\n",
            "|    ep_rew_mean      | 447      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2936     |\n",
            "|    fps              | 269      |\n",
            "|    time_elapsed     | 2328     |\n",
            "|    total_timesteps  | 627849   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0206   |\n",
            "|    n_updates        | 131962   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.23e+03 |\n",
            "|    ep_rew_mean      | 443      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2940     |\n",
            "|    fps              | 269      |\n",
            "|    time_elapsed     | 2332     |\n",
            "|    total_timesteps  | 629040   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0142   |\n",
            "|    n_updates        | 132259   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.24e+03 |\n",
            "|    ep_rew_mean      | 447      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2944     |\n",
            "|    fps              | 269      |\n",
            "|    time_elapsed     | 2337     |\n",
            "|    total_timesteps  | 630433   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0554   |\n",
            "|    n_updates        | 132608   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.24e+03 |\n",
            "|    ep_rew_mean      | 447      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2948     |\n",
            "|    fps              | 269      |\n",
            "|    time_elapsed     | 2342     |\n",
            "|    total_timesteps  | 631475   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0191   |\n",
            "|    n_updates        | 132868   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.25e+03 |\n",
            "|    ep_rew_mean      | 450      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2952     |\n",
            "|    fps              | 269      |\n",
            "|    time_elapsed     | 2345     |\n",
            "|    total_timesteps  | 632280   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0312   |\n",
            "|    n_updates        | 133069   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.24e+03 |\n",
            "|    ep_rew_mean      | 447      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2956     |\n",
            "|    fps              | 269      |\n",
            "|    time_elapsed     | 2351     |\n",
            "|    total_timesteps  | 634034   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.026    |\n",
            "|    n_updates        | 133508   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.23e+03 |\n",
            "|    ep_rew_mean      | 446      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2960     |\n",
            "|    fps              | 269      |\n",
            "|    time_elapsed     | 2354     |\n",
            "|    total_timesteps  | 634647   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0119   |\n",
            "|    n_updates        | 133661   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.24e+03 |\n",
            "|    ep_rew_mean      | 450      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2964     |\n",
            "|    fps              | 269      |\n",
            "|    time_elapsed     | 2358     |\n",
            "|    total_timesteps  | 635885   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0169   |\n",
            "|    n_updates        | 133971   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.22e+03 |\n",
            "|    ep_rew_mean      | 448      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2968     |\n",
            "|    fps              | 269      |\n",
            "|    time_elapsed     | 2365     |\n",
            "|    total_timesteps  | 637725   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0175   |\n",
            "|    n_updates        | 134431   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.21e+03 |\n",
            "|    ep_rew_mean      | 449      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2972     |\n",
            "|    fps              | 269      |\n",
            "|    time_elapsed     | 2369     |\n",
            "|    total_timesteps  | 638920   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0357   |\n",
            "|    n_updates        | 134729   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.2e+03  |\n",
            "|    ep_rew_mean      | 448      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2976     |\n",
            "|    fps              | 269      |\n",
            "|    time_elapsed     | 2374     |\n",
            "|    total_timesteps  | 640210   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0249   |\n",
            "|    n_updates        | 135052   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.21e+03 |\n",
            "|    ep_rew_mean      | 449      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2980     |\n",
            "|    fps              | 269      |\n",
            "|    time_elapsed     | 2379     |\n",
            "|    total_timesteps  | 641422   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0143   |\n",
            "|    n_updates        | 135355   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.22e+03 |\n",
            "|    ep_rew_mean      | 447      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2984     |\n",
            "|    fps              | 269      |\n",
            "|    time_elapsed     | 2384     |\n",
            "|    total_timesteps  | 642865   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0136   |\n",
            "|    n_updates        | 135716   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.24e+03 |\n",
            "|    ep_rew_mean      | 451      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2988     |\n",
            "|    fps              | 269      |\n",
            "|    time_elapsed     | 2391     |\n",
            "|    total_timesteps  | 644707   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0231   |\n",
            "|    n_updates        | 136176   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.27e+03 |\n",
            "|    ep_rew_mean      | 455      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2992     |\n",
            "|    fps              | 269      |\n",
            "|    time_elapsed     | 2397     |\n",
            "|    total_timesteps  | 646304   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0347   |\n",
            "|    n_updates        | 136575   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.27e+03 |\n",
            "|    ep_rew_mean      | 455      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2996     |\n",
            "|    fps              | 269      |\n",
            "|    time_elapsed     | 2402     |\n",
            "|    total_timesteps  | 647517   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00848  |\n",
            "|    n_updates        | 136879   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.28e+03 |\n",
            "|    ep_rew_mean      | 455      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3000     |\n",
            "|    fps              | 269      |\n",
            "|    time_elapsed     | 2406     |\n",
            "|    total_timesteps  | 648731   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0385   |\n",
            "|    n_updates        | 137182   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=650000, episode_reward=475.00 +/- 153.72\n",
            "Episode length: 3654.80 +/- 800.32\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 3.65e+03 |\n",
            "|    mean_reward      | 475      |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 650000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0419   |\n",
            "|    n_updates        | 137499   |\n",
            "----------------------------------\n",
            "New best mean reward!\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.3e+03  |\n",
            "|    ep_rew_mean      | 457      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3004     |\n",
            "|    fps              | 268      |\n",
            "|    time_elapsed     | 2426     |\n",
            "|    total_timesteps  | 651182   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.014    |\n",
            "|    n_updates        | 137795   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.31e+03 |\n",
            "|    ep_rew_mean      | 460      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3008     |\n",
            "|    fps              | 268      |\n",
            "|    time_elapsed     | 2428     |\n",
            "|    total_timesteps  | 651966   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0245   |\n",
            "|    n_updates        | 137991   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.31e+03 |\n",
            "|    ep_rew_mean      | 458      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3012     |\n",
            "|    fps              | 268      |\n",
            "|    time_elapsed     | 2433     |\n",
            "|    total_timesteps  | 653289   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0185   |\n",
            "|    n_updates        | 138322   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.31e+03 |\n",
            "|    ep_rew_mean      | 459      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3016     |\n",
            "|    fps              | 268      |\n",
            "|    time_elapsed     | 2437     |\n",
            "|    total_timesteps  | 654151   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0154   |\n",
            "|    n_updates        | 138537   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.3e+03  |\n",
            "|    ep_rew_mean      | 455      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3020     |\n",
            "|    fps              | 268      |\n",
            "|    time_elapsed     | 2440     |\n",
            "|    total_timesteps  | 655104   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0239   |\n",
            "|    n_updates        | 138775   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.3e+03  |\n",
            "|    ep_rew_mean      | 456      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3024     |\n",
            "|    fps              | 268      |\n",
            "|    time_elapsed     | 2445     |\n",
            "|    total_timesteps  | 656419   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0241   |\n",
            "|    n_updates        | 139104   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.31e+03 |\n",
            "|    ep_rew_mean      | 456      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3028     |\n",
            "|    fps              | 268      |\n",
            "|    time_elapsed     | 2449     |\n",
            "|    total_timesteps  | 657524   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0341   |\n",
            "|    n_updates        | 139380   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.33e+03 |\n",
            "|    ep_rew_mean      | 462      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3032     |\n",
            "|    fps              | 268      |\n",
            "|    time_elapsed     | 2453     |\n",
            "|    total_timesteps  | 658566   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.043    |\n",
            "|    n_updates        | 139641   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.33e+03 |\n",
            "|    ep_rew_mean      | 464      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3036     |\n",
            "|    fps              | 268      |\n",
            "|    time_elapsed     | 2459     |\n",
            "|    total_timesteps  | 660224   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0657   |\n",
            "|    n_updates        | 140055   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.35e+03 |\n",
            "|    ep_rew_mean      | 467      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3040     |\n",
            "|    fps              | 268      |\n",
            "|    time_elapsed     | 2466     |\n",
            "|    total_timesteps  | 662196   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0126   |\n",
            "|    n_updates        | 140548   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.36e+03 |\n",
            "|    ep_rew_mean      | 466      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3044     |\n",
            "|    fps              | 268      |\n",
            "|    time_elapsed     | 2471     |\n",
            "|    total_timesteps  | 663466   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0209   |\n",
            "|    n_updates        | 140866   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.36e+03 |\n",
            "|    ep_rew_mean      | 466      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3048     |\n",
            "|    fps              | 268      |\n",
            "|    time_elapsed     | 2478     |\n",
            "|    total_timesteps  | 665271   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.016    |\n",
            "|    n_updates        | 141317   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.38e+03 |\n",
            "|    ep_rew_mean      | 470      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3052     |\n",
            "|    fps              | 268      |\n",
            "|    time_elapsed     | 2481     |\n",
            "|    total_timesteps  | 666095   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0121   |\n",
            "|    n_updates        | 141523   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.4e+03  |\n",
            "|    ep_rew_mean      | 469      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3056     |\n",
            "|    fps              | 268      |\n",
            "|    time_elapsed     | 2486     |\n",
            "|    total_timesteps  | 667395   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0361   |\n",
            "|    n_updates        | 141848   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.4e+03  |\n",
            "|    ep_rew_mean      | 470      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3060     |\n",
            "|    fps              | 268      |\n",
            "|    time_elapsed     | 2491     |\n",
            "|    total_timesteps  | 668794   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0421   |\n",
            "|    n_updates        | 142198   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.44e+03 |\n",
            "|    ep_rew_mean      | 477      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3064     |\n",
            "|    fps              | 268      |\n",
            "|    time_elapsed     | 2499     |\n",
            "|    total_timesteps  | 670817   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0243   |\n",
            "|    n_updates        | 142704   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.43e+03 |\n",
            "|    ep_rew_mean      | 479      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3068     |\n",
            "|    fps              | 268      |\n",
            "|    time_elapsed     | 2503     |\n",
            "|    total_timesteps  | 671970   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0193   |\n",
            "|    n_updates        | 142992   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.46e+03 |\n",
            "|    ep_rew_mean      | 481      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3072     |\n",
            "|    fps              | 268      |\n",
            "|    time_elapsed     | 2507     |\n",
            "|    total_timesteps  | 673097   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0113   |\n",
            "|    n_updates        | 143274   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.45e+03 |\n",
            "|    ep_rew_mean      | 479      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3076     |\n",
            "|    fps              | 268      |\n",
            "|    time_elapsed     | 2512     |\n",
            "|    total_timesteps  | 674325   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0217   |\n",
            "|    n_updates        | 143581   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=675000, episode_reward=480.00 +/- 134.94\n",
            "Episode length: 3544.60 +/- 828.73\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 3.54e+03 |\n",
            "|    mean_reward      | 480      |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 675000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0126   |\n",
            "|    n_updates        | 143749   |\n",
            "----------------------------------\n",
            "New best mean reward!\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.45e+03 |\n",
            "|    ep_rew_mean      | 479      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3080     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 2525     |\n",
            "|    total_timesteps  | 675267   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0201   |\n",
            "|    n_updates        | 143816   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.48e+03 |\n",
            "|    ep_rew_mean      | 482      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3084     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 2531     |\n",
            "|    total_timesteps  | 677119   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0179   |\n",
            "|    n_updates        | 144279   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.48e+03 |\n",
            "|    ep_rew_mean      | 482      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3088     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 2536     |\n",
            "|    total_timesteps  | 678045   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0153   |\n",
            "|    n_updates        | 144511   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.49e+03 |\n",
            "|    ep_rew_mean      | 482      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3092     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 2539     |\n",
            "|    total_timesteps  | 678988   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.03     |\n",
            "|    n_updates        | 144746   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.52e+03 |\n",
            "|    ep_rew_mean      | 491      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3096     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 2544     |\n",
            "|    total_timesteps  | 680159   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00548  |\n",
            "|    n_updates        | 145039   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.54e+03 |\n",
            "|    ep_rew_mean      | 494      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3100     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 2549     |\n",
            "|    total_timesteps  | 681582   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0117   |\n",
            "|    n_updates        | 145395   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.56e+03 |\n",
            "|    ep_rew_mean      | 501      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3104     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 2556     |\n",
            "|    total_timesteps  | 683545   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0178   |\n",
            "|    n_updates        | 145886   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.55e+03 |\n",
            "|    ep_rew_mean      | 500      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3108     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 2559     |\n",
            "|    total_timesteps  | 684207   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0214   |\n",
            "|    n_updates        | 146051   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.53e+03 |\n",
            "|    ep_rew_mean      | 497      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3112     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 2562     |\n",
            "|    total_timesteps  | 684847   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0396   |\n",
            "|    n_updates        | 146211   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.53e+03 |\n",
            "|    ep_rew_mean      | 496      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3116     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 2567     |\n",
            "|    total_timesteps  | 686252   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0272   |\n",
            "|    n_updates        | 146562   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.56e+03 |\n",
            "|    ep_rew_mean      | 499      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3120     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 2574     |\n",
            "|    total_timesteps  | 688204   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0165   |\n",
            "|    n_updates        | 147050   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.59e+03 |\n",
            "|    ep_rew_mean      | 508      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3124     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 2583     |\n",
            "|    total_timesteps  | 690777   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0247   |\n",
            "|    n_updates        | 147694   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.57e+03 |\n",
            "|    ep_rew_mean      | 504      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3128     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 2587     |\n",
            "|    total_timesteps  | 691724   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0171   |\n",
            "|    n_updates        | 147930   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.57e+03 |\n",
            "|    ep_rew_mean      | 504      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3132     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 2593     |\n",
            "|    total_timesteps  | 693302   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0239   |\n",
            "|    n_updates        | 148325   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.57e+03 |\n",
            "|    ep_rew_mean      | 507      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3136     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 2598     |\n",
            "|    total_timesteps  | 694647   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0263   |\n",
            "|    n_updates        | 148661   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.58e+03 |\n",
            "|    ep_rew_mean      | 508      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3140     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 2602     |\n",
            "|    total_timesteps  | 695742   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0348   |\n",
            "|    n_updates        | 148935   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.61e+03 |\n",
            "|    ep_rew_mean      | 514      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3144     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 2606     |\n",
            "|    total_timesteps  | 696938   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0191   |\n",
            "|    n_updates        | 149234   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.61e+03 |\n",
            "|    ep_rew_mean      | 516      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3148     |\n",
            "|    fps              | 267      |\n",
            "|    time_elapsed     | 2614     |\n",
            "|    total_timesteps  | 698927   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0571   |\n",
            "|    n_updates        | 149731   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=700000, episode_reward=508.00 +/- 156.35\n",
            "Episode length: 3447.20 +/- 825.08\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 3.45e+03 |\n",
            "|    mean_reward      | 508      |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 700000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0559   |\n",
            "|    n_updates        | 149999   |\n",
            "----------------------------------\n",
            "New best mean reward!\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.62e+03 |\n",
            "|    ep_rew_mean      | 518      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3152     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 2628     |\n",
            "|    total_timesteps  | 700248   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0392   |\n",
            "|    n_updates        | 150061   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.63e+03 |\n",
            "|    ep_rew_mean      | 524      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3156     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 2632     |\n",
            "|    total_timesteps  | 701330   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0133   |\n",
            "|    n_updates        | 150332   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.66e+03 |\n",
            "|    ep_rew_mean      | 527      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3160     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 2643     |\n",
            "|    total_timesteps  | 704208   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0147   |\n",
            "|    n_updates        | 151051   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.72e+03 |\n",
            "|    ep_rew_mean      | 533      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3164     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 2651     |\n",
            "|    total_timesteps  | 706427   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00629  |\n",
            "|    n_updates        | 151606   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.71e+03 |\n",
            "|    ep_rew_mean      | 533      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3168     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 2659     |\n",
            "|    total_timesteps  | 708293   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0138   |\n",
            "|    n_updates        | 152073   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.7e+03  |\n",
            "|    ep_rew_mean      | 530      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3172     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 2662     |\n",
            "|    total_timesteps  | 709250   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0496   |\n",
            "|    n_updates        | 152312   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.71e+03 |\n",
            "|    ep_rew_mean      | 530      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3176     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 2672     |\n",
            "|    total_timesteps  | 711754   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0335   |\n",
            "|    n_updates        | 152938   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.76e+03 |\n",
            "|    ep_rew_mean      | 536      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3180     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 2676     |\n",
            "|    total_timesteps  | 712961   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0196   |\n",
            "|    n_updates        | 153240   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.77e+03 |\n",
            "|    ep_rew_mean      | 536      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3184     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 2681     |\n",
            "|    total_timesteps  | 714379   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0145   |\n",
            "|    n_updates        | 153594   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.77e+03 |\n",
            "|    ep_rew_mean      | 535      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3188     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 2687     |\n",
            "|    total_timesteps  | 715923   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0124   |\n",
            "|    n_updates        | 153980   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.8e+03  |\n",
            "|    ep_rew_mean      | 539      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3192     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 2692     |\n",
            "|    total_timesteps  | 717296   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0695   |\n",
            "|    n_updates        | 154323   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.8e+03  |\n",
            "|    ep_rew_mean      | 538      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3196     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 2699     |\n",
            "|    total_timesteps  | 719179   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0229   |\n",
            "|    n_updates        | 154794   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.81e+03 |\n",
            "|    ep_rew_mean      | 541      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3200     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 2705     |\n",
            "|    total_timesteps  | 720839   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.022    |\n",
            "|    n_updates        | 155209   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.83e+03 |\n",
            "|    ep_rew_mean      | 551      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3204     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 2711     |\n",
            "|    total_timesteps  | 722448   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0105   |\n",
            "|    n_updates        | 155611   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.85e+03 |\n",
            "|    ep_rew_mean      | 552      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3208     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 2717     |\n",
            "|    total_timesteps  | 724183   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00983  |\n",
            "|    n_updates        | 156045   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.85e+03 |\n",
            "|    ep_rew_mean      | 550      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3212     |\n",
            "|    fps              | 266      |\n",
            "|    time_elapsed     | 2720     |\n",
            "|    total_timesteps  | 724894   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00776  |\n",
            "|    n_updates        | 156223   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=725000, episode_reward=599.00 +/- 264.98\n",
            "Episode length: 4569.00 +/- 1197.75\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 4.57e+03 |\n",
            "|    mean_reward      | 599      |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 725000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0341   |\n",
            "|    n_updates        | 156249   |\n",
            "----------------------------------\n",
            "New best mean reward!\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.89e+03 |\n",
            "|    ep_rew_mean      | 556      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3216     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 2740     |\n",
            "|    total_timesteps  | 727062   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0111   |\n",
            "|    n_updates        | 156765   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.89e+03 |\n",
            "|    ep_rew_mean      | 560      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3220     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 2746     |\n",
            "|    total_timesteps  | 728656   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0125   |\n",
            "|    n_updates        | 157163   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.92e+03 |\n",
            "|    ep_rew_mean      | 563      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3224     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 2752     |\n",
            "|    total_timesteps  | 730141   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0151   |\n",
            "|    n_updates        | 157535   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.94e+03 |\n",
            "|    ep_rew_mean      | 562      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3228     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 2761     |\n",
            "|    total_timesteps  | 732631   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0221   |\n",
            "|    n_updates        | 158157   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.96e+03 |\n",
            "|    ep_rew_mean      | 564      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3232     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 2765     |\n",
            "|    total_timesteps  | 733931   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0207   |\n",
            "|    n_updates        | 158482   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.98e+03 |\n",
            "|    ep_rew_mean      | 565      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3236     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 2775     |\n",
            "|    total_timesteps  | 736690   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0263   |\n",
            "|    n_updates        | 159172   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.98e+03 |\n",
            "|    ep_rew_mean      | 564      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3240     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 2782     |\n",
            "|    total_timesteps  | 738274   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0147   |\n",
            "|    n_updates        | 159568   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.98e+03 |\n",
            "|    ep_rew_mean      | 562      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3244     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 2787     |\n",
            "|    total_timesteps  | 739693   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0214   |\n",
            "|    n_updates        | 159923   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.98e+03 |\n",
            "|    ep_rew_mean      | 562      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3248     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 2792     |\n",
            "|    total_timesteps  | 740872   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0293   |\n",
            "|    n_updates        | 160217   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.98e+03 |\n",
            "|    ep_rew_mean      | 561      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3252     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 2800     |\n",
            "|    total_timesteps  | 743209   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0305   |\n",
            "|    n_updates        | 160802   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.97e+03 |\n",
            "|    ep_rew_mean      | 564      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3256     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 2804     |\n",
            "|    total_timesteps  | 744086   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0169   |\n",
            "|    n_updates        | 161021   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.96e+03 |\n",
            "|    ep_rew_mean      | 557      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3260     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 2808     |\n",
            "|    total_timesteps  | 745233   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0148   |\n",
            "|    n_updates        | 161308   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.96e+03 |\n",
            "|    ep_rew_mean      | 557      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3264     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 2813     |\n",
            "|    total_timesteps  | 746632   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0597   |\n",
            "|    n_updates        | 161657   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.96e+03 |\n",
            "|    ep_rew_mean      | 558      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3268     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 2819     |\n",
            "|    total_timesteps  | 748296   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0212   |\n",
            "|    n_updates        | 162073   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.95e+03 |\n",
            "|    ep_rew_mean      | 556      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3272     |\n",
            "|    fps              | 265      |\n",
            "|    time_elapsed     | 2823     |\n",
            "|    total_timesteps  | 749421   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0204   |\n",
            "|    n_updates        | 162355   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=750000, episode_reward=638.00 +/- 97.86\n",
            "Episode length: 4243.40 +/- 565.05\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 4.24e+03 |\n",
            "|    mean_reward      | 638      |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 750000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0173   |\n",
            "|    n_updates        | 162499   |\n",
            "----------------------------------\n",
            "New best mean reward!\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.98e+03 |\n",
            "|    ep_rew_mean      | 562      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3276     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 2842     |\n",
            "|    total_timesteps  | 751445   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00751  |\n",
            "|    n_updates        | 162861   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.01e+03 |\n",
            "|    ep_rew_mean      | 563      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3280     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 2850     |\n",
            "|    total_timesteps  | 753683   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00801  |\n",
            "|    n_updates        | 163420   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.02e+03 |\n",
            "|    ep_rew_mean      | 565      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3284     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 2855     |\n",
            "|    total_timesteps  | 754674   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0295   |\n",
            "|    n_updates        | 163668   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4e+03    |\n",
            "|    ep_rew_mean      | 560      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3288     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 2859     |\n",
            "|    total_timesteps  | 755909   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0467   |\n",
            "|    n_updates        | 163977   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.02e+03 |\n",
            "|    ep_rew_mean      | 562      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3292     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 2864     |\n",
            "|    total_timesteps  | 757227   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0289   |\n",
            "|    n_updates        | 164306   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.01e+03 |\n",
            "|    ep_rew_mean      | 560      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3296     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 2867     |\n",
            "|    total_timesteps  | 758135   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0179   |\n",
            "|    n_updates        | 164533   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.02e+03 |\n",
            "|    ep_rew_mean      | 561      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3300     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 2871     |\n",
            "|    total_timesteps  | 759264   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0238   |\n",
            "|    n_updates        | 164815   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.01e+03 |\n",
            "|    ep_rew_mean      | 558      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3304     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 2877     |\n",
            "|    total_timesteps  | 760598   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0117   |\n",
            "|    n_updates        | 165149   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.03e+03 |\n",
            "|    ep_rew_mean      | 561      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3308     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 2883     |\n",
            "|    total_timesteps  | 762457   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0112   |\n",
            "|    n_updates        | 165614   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.05e+03 |\n",
            "|    ep_rew_mean      | 562      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3312     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 2891     |\n",
            "|    total_timesteps  | 764554   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0263   |\n",
            "|    n_updates        | 166138   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.03e+03 |\n",
            "|    ep_rew_mean      | 563      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3316     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 2895     |\n",
            "|    total_timesteps  | 765655   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0121   |\n",
            "|    n_updates        | 166413   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.04e+03 |\n",
            "|    ep_rew_mean      | 564      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3320     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 2900     |\n",
            "|    total_timesteps  | 766931   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0148   |\n",
            "|    n_updates        | 166732   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.06e+03 |\n",
            "|    ep_rew_mean      | 570      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3324     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 2906     |\n",
            "|    total_timesteps  | 768598   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.111    |\n",
            "|    n_updates        | 167149   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.03e+03 |\n",
            "|    ep_rew_mean      | 562      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3328     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 2912     |\n",
            "|    total_timesteps  | 770211   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0147   |\n",
            "|    n_updates        | 167552   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.04e+03 |\n",
            "|    ep_rew_mean      | 561      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3332     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 2919     |\n",
            "|    total_timesteps  | 771950   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0238   |\n",
            "|    n_updates        | 167987   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.06e+03 |\n",
            "|    ep_rew_mean      | 564      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3336     |\n",
            "|    fps              | 264      |\n",
            "|    time_elapsed     | 2928     |\n",
            "|    total_timesteps  | 774463   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00955  |\n",
            "|    n_updates        | 168615   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=775000, episode_reward=495.00 +/- 156.14\n",
            "Episode length: 3681.80 +/- 956.78\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 3.68e+03 |\n",
            "|    mean_reward      | 495      |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 775000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0327   |\n",
            "|    n_updates        | 168749   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.06e+03 |\n",
            "|    ep_rew_mean      | 561      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3340     |\n",
            "|    fps              | 263      |\n",
            "|    time_elapsed     | 2945     |\n",
            "|    total_timesteps  | 776310   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0445   |\n",
            "|    n_updates        | 169077   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.04e+03 |\n",
            "|    ep_rew_mean      | 559      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3344     |\n",
            "|    fps              | 263      |\n",
            "|    time_elapsed     | 2950     |\n",
            "|    total_timesteps  | 777632   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0313   |\n",
            "|    n_updates        | 169407   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.09e+03 |\n",
            "|    ep_rew_mean      | 568      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3348     |\n",
            "|    fps              | 263      |\n",
            "|    time_elapsed     | 2960     |\n",
            "|    total_timesteps  | 780417   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.059    |\n",
            "|    n_updates        | 170104   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.1e+03  |\n",
            "|    ep_rew_mean      | 567      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3352     |\n",
            "|    fps              | 263      |\n",
            "|    time_elapsed     | 2963     |\n",
            "|    total_timesteps  | 781239   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0516   |\n",
            "|    n_updates        | 170309   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.13e+03 |\n",
            "|    ep_rew_mean      | 570      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3356     |\n",
            "|    fps              | 263      |\n",
            "|    time_elapsed     | 2971     |\n",
            "|    total_timesteps  | 783444   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0184   |\n",
            "|    n_updates        | 170860   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.11e+03 |\n",
            "|    ep_rew_mean      | 568      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3360     |\n",
            "|    fps              | 263      |\n",
            "|    time_elapsed     | 2977     |\n",
            "|    total_timesteps  | 784758   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0261   |\n",
            "|    n_updates        | 171189   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.12e+03 |\n",
            "|    ep_rew_mean      | 566      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3364     |\n",
            "|    fps              | 263      |\n",
            "|    time_elapsed     | 2982     |\n",
            "|    total_timesteps  | 786428   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0216   |\n",
            "|    n_updates        | 171606   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.17e+03 |\n",
            "|    ep_rew_mean      | 574      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3368     |\n",
            "|    fps              | 263      |\n",
            "|    time_elapsed     | 2987     |\n",
            "|    total_timesteps  | 787615   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0198   |\n",
            "|    n_updates        | 171903   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.16e+03 |\n",
            "|    ep_rew_mean      | 573      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3372     |\n",
            "|    fps              | 263      |\n",
            "|    time_elapsed     | 2991     |\n",
            "|    total_timesteps  | 788586   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0415   |\n",
            "|    n_updates        | 172146   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.16e+03 |\n",
            "|    ep_rew_mean      | 577      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3376     |\n",
            "|    fps              | 263      |\n",
            "|    time_elapsed     | 2995     |\n",
            "|    total_timesteps  | 789868   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00807  |\n",
            "|    n_updates        | 172466   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.11e+03 |\n",
            "|    ep_rew_mean      | 570      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3380     |\n",
            "|    fps              | 263      |\n",
            "|    time_elapsed     | 3003     |\n",
            "|    total_timesteps  | 791865   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0146   |\n",
            "|    n_updates        | 172966   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.12e+03 |\n",
            "|    ep_rew_mean      | 570      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3384     |\n",
            "|    fps              | 263      |\n",
            "|    time_elapsed     | 3009     |\n",
            "|    total_timesteps  | 793582   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0282   |\n",
            "|    n_updates        | 173395   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.13e+03 |\n",
            "|    ep_rew_mean      | 570      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3388     |\n",
            "|    fps              | 263      |\n",
            "|    time_elapsed     | 3017     |\n",
            "|    total_timesteps  | 795814   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0479   |\n",
            "|    n_updates        | 173953   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.13e+03 |\n",
            "|    ep_rew_mean      | 569      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3392     |\n",
            "|    fps              | 263      |\n",
            "|    time_elapsed     | 3022     |\n",
            "|    total_timesteps  | 797114   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0228   |\n",
            "|    n_updates        | 174278   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.12e+03 |\n",
            "|    ep_rew_mean      | 568      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3396     |\n",
            "|    fps              | 263      |\n",
            "|    time_elapsed     | 3031     |\n",
            "|    total_timesteps  | 799444   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.011    |\n",
            "|    n_updates        | 174860   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=800000, episode_reward=631.00 +/- 100.12\n",
            "Episode length: 4034.20 +/- 266.94\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 4.03e+03 |\n",
            "|    mean_reward      | 631      |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 800000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0219   |\n",
            "|    n_updates        | 174999   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.13e+03 |\n",
            "|    ep_rew_mean      | 572      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3400     |\n",
            "|    fps              | 262      |\n",
            "|    time_elapsed     | 3050     |\n",
            "|    total_timesteps  | 801415   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.012    |\n",
            "|    n_updates        | 175353   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.12e+03 |\n",
            "|    ep_rew_mean      | 567      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3404     |\n",
            "|    fps              | 262      |\n",
            "|    time_elapsed     | 3052     |\n",
            "|    total_timesteps  | 802215   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.028    |\n",
            "|    n_updates        | 175553   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.11e+03 |\n",
            "|    ep_rew_mean      | 568      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3408     |\n",
            "|    fps              | 262      |\n",
            "|    time_elapsed     | 3059     |\n",
            "|    total_timesteps  | 804071   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0332   |\n",
            "|    n_updates        | 176017   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.11e+03 |\n",
            "|    ep_rew_mean      | 567      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3412     |\n",
            "|    fps              | 262      |\n",
            "|    time_elapsed     | 3066     |\n",
            "|    total_timesteps  | 805903   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0145   |\n",
            "|    n_updates        | 176475   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.06e+03 |\n",
            "|    ep_rew_mean      | 564      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3416     |\n",
            "|    fps              | 262      |\n",
            "|    time_elapsed     | 3069     |\n",
            "|    total_timesteps  | 806906   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0241   |\n",
            "|    n_updates        | 176726   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.06e+03 |\n",
            "|    ep_rew_mean      | 564      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3420     |\n",
            "|    fps              | 262      |\n",
            "|    time_elapsed     | 3077     |\n",
            "|    total_timesteps  | 809023   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0164   |\n",
            "|    n_updates        | 177255   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.09e+03 |\n",
            "|    ep_rew_mean      | 567      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3424     |\n",
            "|    fps              | 262      |\n",
            "|    time_elapsed     | 3082     |\n",
            "|    total_timesteps  | 810267   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0245   |\n",
            "|    n_updates        | 177566   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.04e+03 |\n",
            "|    ep_rew_mean      | 561      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3428     |\n",
            "|    fps              | 262      |\n",
            "|    time_elapsed     | 3088     |\n",
            "|    total_timesteps  | 811857   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00971  |\n",
            "|    n_updates        | 177964   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.02e+03 |\n",
            "|    ep_rew_mean      | 561      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3432     |\n",
            "|    fps              | 262      |\n",
            "|    time_elapsed     | 3093     |\n",
            "|    total_timesteps  | 813389   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0112   |\n",
            "|    n_updates        | 178347   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.01e+03 |\n",
            "|    ep_rew_mean      | 562      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3436     |\n",
            "|    fps              | 262      |\n",
            "|    time_elapsed     | 3099     |\n",
            "|    total_timesteps  | 814721   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0108   |\n",
            "|    n_updates        | 178680   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4e+03    |\n",
            "|    ep_rew_mean      | 561      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3440     |\n",
            "|    fps              | 262      |\n",
            "|    time_elapsed     | 3106     |\n",
            "|    total_timesteps  | 816771   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0313   |\n",
            "|    n_updates        | 179192   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.01e+03 |\n",
            "|    ep_rew_mean      | 562      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3444     |\n",
            "|    fps              | 262      |\n",
            "|    time_elapsed     | 3112     |\n",
            "|    total_timesteps  | 818373   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0169   |\n",
            "|    n_updates        | 179593   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.02e+03 |\n",
            "|    ep_rew_mean      | 565      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3448     |\n",
            "|    fps              | 262      |\n",
            "|    time_elapsed     | 3119     |\n",
            "|    total_timesteps  | 820309   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0449   |\n",
            "|    n_updates        | 180077   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4e+03    |\n",
            "|    ep_rew_mean      | 558      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3452     |\n",
            "|    fps              | 262      |\n",
            "|    time_elapsed     | 3124     |\n",
            "|    total_timesteps  | 821602   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0103   |\n",
            "|    n_updates        | 180400   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.05e+03 |\n",
            "|    ep_rew_mean      | 568      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3456     |\n",
            "|    fps              | 263      |\n",
            "|    time_elapsed     | 3131     |\n",
            "|    total_timesteps  | 823616   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0144   |\n",
            "|    n_updates        | 180903   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=825000, episode_reward=524.00 +/- 139.98\n",
            "Episode length: 4984.20 +/- 1480.17\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 4.98e+03 |\n",
            "|    mean_reward      | 524      |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 825000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0264   |\n",
            "|    n_updates        | 181249   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.07e+03 |\n",
            "|    ep_rew_mean      | 571      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3460     |\n",
            "|    fps              | 261      |\n",
            "|    time_elapsed     | 3151     |\n",
            "|    total_timesteps  | 825476   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0323   |\n",
            "|    n_updates        | 181368   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.04e+03 |\n",
            "|    ep_rew_mean      | 570      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3464     |\n",
            "|    fps              | 261      |\n",
            "|    time_elapsed     | 3158     |\n",
            "|    total_timesteps  | 827244   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0177   |\n",
            "|    n_updates        | 181810   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.04e+03 |\n",
            "|    ep_rew_mean      | 569      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3468     |\n",
            "|    fps              | 261      |\n",
            "|    time_elapsed     | 3164     |\n",
            "|    total_timesteps  | 828828   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0299   |\n",
            "|    n_updates        | 182206   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.02e+03 |\n",
            "|    ep_rew_mean      | 567      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3472     |\n",
            "|    fps              | 261      |\n",
            "|    time_elapsed     | 3171     |\n",
            "|    total_timesteps  | 830826   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0229   |\n",
            "|    n_updates        | 182706   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.01e+03 |\n",
            "|    ep_rew_mean      | 571      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3476     |\n",
            "|    fps              | 261      |\n",
            "|    time_elapsed     | 3178     |\n",
            "|    total_timesteps  | 832659   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0741   |\n",
            "|    n_updates        | 183164   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4e+03    |\n",
            "|    ep_rew_mean      | 569      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3480     |\n",
            "|    fps              | 261      |\n",
            "|    time_elapsed     | 3184     |\n",
            "|    total_timesteps  | 834253   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.052    |\n",
            "|    n_updates        | 183563   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.06e+03 |\n",
            "|    ep_rew_mean      | 575      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3484     |\n",
            "|    fps              | 262      |\n",
            "|    time_elapsed     | 3193     |\n",
            "|    total_timesteps  | 836829   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0202   |\n",
            "|    n_updates        | 184207   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.05e+03 |\n",
            "|    ep_rew_mean      | 572      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3488     |\n",
            "|    fps              | 262      |\n",
            "|    time_elapsed     | 3197     |\n",
            "|    total_timesteps  | 837813   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0129   |\n",
            "|    n_updates        | 184453   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.06e+03 |\n",
            "|    ep_rew_mean      | 576      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3492     |\n",
            "|    fps              | 262      |\n",
            "|    time_elapsed     | 3203     |\n",
            "|    total_timesteps  | 839631   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.104    |\n",
            "|    n_updates        | 184907   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.09e+03 |\n",
            "|    ep_rew_mean      | 580      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3496     |\n",
            "|    fps              | 262      |\n",
            "|    time_elapsed     | 3210     |\n",
            "|    total_timesteps  | 841356   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0171   |\n",
            "|    n_updates        | 185338   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.09e+03 |\n",
            "|    ep_rew_mean      | 583      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3500     |\n",
            "|    fps              | 262      |\n",
            "|    time_elapsed     | 3220     |\n",
            "|    total_timesteps  | 843926   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00799  |\n",
            "|    n_updates        | 185981   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.1e+03  |\n",
            "|    ep_rew_mean      | 586      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3504     |\n",
            "|    fps              | 262      |\n",
            "|    time_elapsed     | 3224     |\n",
            "|    total_timesteps  | 845068   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0163   |\n",
            "|    n_updates        | 186266   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.09e+03 |\n",
            "|    ep_rew_mean      | 590      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3508     |\n",
            "|    fps              | 262      |\n",
            "|    time_elapsed     | 3231     |\n",
            "|    total_timesteps  | 847002   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0121   |\n",
            "|    n_updates        | 186750   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.1e+03  |\n",
            "|    ep_rew_mean      | 590      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3512     |\n",
            "|    fps              | 262      |\n",
            "|    time_elapsed     | 3238     |\n",
            "|    total_timesteps  | 849029   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0207   |\n",
            "|    n_updates        | 187257   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=850000, episode_reward=554.00 +/- 129.51\n",
            "Episode length: 3705.80 +/- 861.88\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 3.71e+03 |\n",
            "|    mean_reward      | 554      |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 850000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0122   |\n",
            "|    n_updates        | 187499   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.1e+03  |\n",
            "|    ep_rew_mean      | 592      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3516     |\n",
            "|    fps              | 261      |\n",
            "|    time_elapsed     | 3255     |\n",
            "|    total_timesteps  | 850859   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00965  |\n",
            "|    n_updates        | 187714   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.12e+03 |\n",
            "|    ep_rew_mean      | 593      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3520     |\n",
            "|    fps              | 261      |\n",
            "|    time_elapsed     | 3260     |\n",
            "|    total_timesteps  | 852303   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0177   |\n",
            "|    n_updates        | 188075   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.14e+03 |\n",
            "|    ep_rew_mean      | 593      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3524     |\n",
            "|    fps              | 261      |\n",
            "|    time_elapsed     | 3266     |\n",
            "|    total_timesteps  | 854011   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0276   |\n",
            "|    n_updates        | 188502   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.14e+03 |\n",
            "|    ep_rew_mean      | 594      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3528     |\n",
            "|    fps              | 261      |\n",
            "|    time_elapsed     | 3271     |\n",
            "|    total_timesteps  | 855158   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00802  |\n",
            "|    n_updates        | 188789   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.12e+03 |\n",
            "|    ep_rew_mean      | 592      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3532     |\n",
            "|    fps              | 261      |\n",
            "|    time_elapsed     | 3275     |\n",
            "|    total_timesteps  | 856309   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0155   |\n",
            "|    n_updates        | 189077   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.14e+03 |\n",
            "|    ep_rew_mean      | 593      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3536     |\n",
            "|    fps              | 261      |\n",
            "|    time_elapsed     | 3280     |\n",
            "|    total_timesteps  | 857698   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.01     |\n",
            "|    n_updates        | 189424   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.13e+03 |\n",
            "|    ep_rew_mean      | 591      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3540     |\n",
            "|    fps              | 261      |\n",
            "|    time_elapsed     | 3285     |\n",
            "|    total_timesteps  | 859186   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0229   |\n",
            "|    n_updates        | 189796   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.14e+03 |\n",
            "|    ep_rew_mean      | 594      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3544     |\n",
            "|    fps              | 261      |\n",
            "|    time_elapsed     | 3293     |\n",
            "|    total_timesteps  | 861235   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0124   |\n",
            "|    n_updates        | 190308   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.14e+03 |\n",
            "|    ep_rew_mean      | 598      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3548     |\n",
            "|    fps              | 261      |\n",
            "|    time_elapsed     | 3299     |\n",
            "|    total_timesteps  | 862892   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.024    |\n",
            "|    n_updates        | 190722   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.11e+03 |\n",
            "|    ep_rew_mean      | 594      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3552     |\n",
            "|    fps              | 261      |\n",
            "|    time_elapsed     | 3304     |\n",
            "|    total_timesteps  | 864059   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0801   |\n",
            "|    n_updates        | 191014   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.09e+03 |\n",
            "|    ep_rew_mean      | 590      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3556     |\n",
            "|    fps              | 261      |\n",
            "|    time_elapsed     | 3310     |\n",
            "|    total_timesteps  | 865878   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0383   |\n",
            "|    n_updates        | 191469   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.08e+03 |\n",
            "|    ep_rew_mean      | 587      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3560     |\n",
            "|    fps              | 261      |\n",
            "|    time_elapsed     | 3315     |\n",
            "|    total_timesteps  | 867138   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0182   |\n",
            "|    n_updates        | 191784   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.07e+03 |\n",
            "|    ep_rew_mean      | 585      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3564     |\n",
            "|    fps              | 261      |\n",
            "|    time_elapsed     | 3319     |\n",
            "|    total_timesteps  | 868207   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0424   |\n",
            "|    n_updates        | 192051   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.06e+03 |\n",
            "|    ep_rew_mean      | 585      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3568     |\n",
            "|    fps              | 261      |\n",
            "|    time_elapsed     | 3328     |\n",
            "|    total_timesteps  | 870703   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0135   |\n",
            "|    n_updates        | 192675   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.08e+03 |\n",
            "|    ep_rew_mean      | 588      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3572     |\n",
            "|    fps              | 261      |\n",
            "|    time_elapsed     | 3333     |\n",
            "|    total_timesteps  | 872157   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0131   |\n",
            "|    n_updates        | 193039   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.09e+03 |\n",
            "|    ep_rew_mean      | 592      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3576     |\n",
            "|    fps              | 261      |\n",
            "|    time_elapsed     | 3339     |\n",
            "|    total_timesteps  | 873582   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0152   |\n",
            "|    n_updates        | 193395   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.06e+03 |\n",
            "|    ep_rew_mean      | 594      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3580     |\n",
            "|    fps              | 261      |\n",
            "|    time_elapsed     | 3344     |\n",
            "|    total_timesteps  | 874928   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.064    |\n",
            "|    n_updates        | 193731   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=875000, episode_reward=672.00 +/- 146.92\n",
            "Episode length: 4144.80 +/- 489.80\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 4.14e+03 |\n",
            "|    mean_reward      | 672      |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 875000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.024    |\n",
            "|    n_updates        | 193749   |\n",
            "----------------------------------\n",
            "New best mean reward!\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.07e+03 |\n",
            "|    ep_rew_mean      | 595      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3584     |\n",
            "|    fps              | 260      |\n",
            "|    time_elapsed     | 3362     |\n",
            "|    total_timesteps  | 877147   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0196   |\n",
            "|    n_updates        | 194286   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.1e+03  |\n",
            "|    ep_rew_mean      | 599      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3588     |\n",
            "|    fps              | 260      |\n",
            "|    time_elapsed     | 3369     |\n",
            "|    total_timesteps  | 878892   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.019    |\n",
            "|    n_updates        | 194722   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.09e+03 |\n",
            "|    ep_rew_mean      | 600      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3592     |\n",
            "|    fps              | 260      |\n",
            "|    time_elapsed     | 3375     |\n",
            "|    total_timesteps  | 880555   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0367   |\n",
            "|    n_updates        | 195138   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.08e+03 |\n",
            "|    ep_rew_mean      | 599      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3596     |\n",
            "|    fps              | 260      |\n",
            "|    time_elapsed     | 3381     |\n",
            "|    total_timesteps  | 882121   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0198   |\n",
            "|    n_updates        | 195530   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.04e+03 |\n",
            "|    ep_rew_mean      | 596      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3600     |\n",
            "|    fps              | 260      |\n",
            "|    time_elapsed     | 3386     |\n",
            "|    total_timesteps  | 883517   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0216   |\n",
            "|    n_updates        | 195879   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.03e+03 |\n",
            "|    ep_rew_mean      | 594      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3604     |\n",
            "|    fps              | 260      |\n",
            "|    time_elapsed     | 3391     |\n",
            "|    total_timesteps  | 884911   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0187   |\n",
            "|    n_updates        | 196227   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.03e+03 |\n",
            "|    ep_rew_mean      | 595      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3608     |\n",
            "|    fps              | 260      |\n",
            "|    time_elapsed     | 3396     |\n",
            "|    total_timesteps  | 886217   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0134   |\n",
            "|    n_updates        | 196554   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.02e+03 |\n",
            "|    ep_rew_mean      | 597      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3612     |\n",
            "|    fps              | 260      |\n",
            "|    time_elapsed     | 3401     |\n",
            "|    total_timesteps  | 887629   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0287   |\n",
            "|    n_updates        | 196907   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.03e+03 |\n",
            "|    ep_rew_mean      | 599      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3616     |\n",
            "|    fps              | 260      |\n",
            "|    time_elapsed     | 3408     |\n",
            "|    total_timesteps  | 889557   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0198   |\n",
            "|    n_updates        | 197389   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.06e+03 |\n",
            "|    ep_rew_mean      | 596      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3620     |\n",
            "|    fps              | 260      |\n",
            "|    time_elapsed     | 3415     |\n",
            "|    total_timesteps  | 891314   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0252   |\n",
            "|    n_updates        | 197828   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.07e+03 |\n",
            "|    ep_rew_mean      | 596      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3624     |\n",
            "|    fps              | 261      |\n",
            "|    time_elapsed     | 3420     |\n",
            "|    total_timesteps  | 892872   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0252   |\n",
            "|    n_updates        | 198217   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.06e+03 |\n",
            "|    ep_rew_mean      | 596      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3628     |\n",
            "|    fps              | 261      |\n",
            "|    time_elapsed     | 3425     |\n",
            "|    total_timesteps  | 894070   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00914  |\n",
            "|    n_updates        | 198517   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.09e+03 |\n",
            "|    ep_rew_mean      | 606      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3632     |\n",
            "|    fps              | 261      |\n",
            "|    time_elapsed     | 3432     |\n",
            "|    total_timesteps  | 896011   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0329   |\n",
            "|    n_updates        | 199002   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.08e+03 |\n",
            "|    ep_rew_mean      | 607      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3636     |\n",
            "|    fps              | 261      |\n",
            "|    time_elapsed     | 3438     |\n",
            "|    total_timesteps  | 897622   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0207   |\n",
            "|    n_updates        | 199405   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.09e+03 |\n",
            "|    ep_rew_mean      | 608      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3640     |\n",
            "|    fps              | 261      |\n",
            "|    time_elapsed     | 3443     |\n",
            "|    total_timesteps  | 899124   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0207   |\n",
            "|    n_updates        | 199780   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=900000, episode_reward=557.00 +/- 126.28\n",
            "Episode length: 3719.00 +/- 575.65\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 3.72e+03 |\n",
            "|    mean_reward      | 557      |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 900000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0362   |\n",
            "|    n_updates        | 199999   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.08e+03 |\n",
            "|    ep_rew_mean      | 603      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3644     |\n",
            "|    fps              | 260      |\n",
            "|    time_elapsed     | 3458     |\n",
            "|    total_timesteps  | 900460   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00946  |\n",
            "|    n_updates        | 200114   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.07e+03 |\n",
            "|    ep_rew_mean      | 603      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3648     |\n",
            "|    fps              | 260      |\n",
            "|    time_elapsed     | 3462     |\n",
            "|    total_timesteps  | 901395   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0735   |\n",
            "|    n_updates        | 200348   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.07e+03 |\n",
            "|    ep_rew_mean      | 606      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3652     |\n",
            "|    fps              | 260      |\n",
            "|    time_elapsed     | 3467     |\n",
            "|    total_timesteps  | 903013   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0206   |\n",
            "|    n_updates        | 200753   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.07e+03 |\n",
            "|    ep_rew_mean      | 604      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3656     |\n",
            "|    fps              | 260      |\n",
            "|    time_elapsed     | 3476     |\n",
            "|    total_timesteps  | 905460   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0259   |\n",
            "|    n_updates        | 201364   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.1e+03  |\n",
            "|    ep_rew_mean      | 608      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3660     |\n",
            "|    fps              | 260      |\n",
            "|    time_elapsed     | 3480     |\n",
            "|    total_timesteps  | 906564   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0193   |\n",
            "|    n_updates        | 201640   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.11e+03 |\n",
            "|    ep_rew_mean      | 606      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3664     |\n",
            "|    fps              | 260      |\n",
            "|    time_elapsed     | 3485     |\n",
            "|    total_timesteps  | 907746   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0336   |\n",
            "|    n_updates        | 201936   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.11e+03 |\n",
            "|    ep_rew_mean      | 606      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3668     |\n",
            "|    fps              | 260      |\n",
            "|    time_elapsed     | 3490     |\n",
            "|    total_timesteps  | 909156   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0154   |\n",
            "|    n_updates        | 202288   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.1e+03  |\n",
            "|    ep_rew_mean      | 606      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3672     |\n",
            "|    fps              | 260      |\n",
            "|    time_elapsed     | 3496     |\n",
            "|    total_timesteps  | 910893   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0155   |\n",
            "|    n_updates        | 202723   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.09e+03 |\n",
            "|    ep_rew_mean      | 604      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3676     |\n",
            "|    fps              | 260      |\n",
            "|    time_elapsed     | 3502     |\n",
            "|    total_timesteps  | 912425   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0262   |\n",
            "|    n_updates        | 203106   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.1e+03  |\n",
            "|    ep_rew_mean      | 604      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3680     |\n",
            "|    fps              | 260      |\n",
            "|    time_elapsed     | 3508     |\n",
            "|    total_timesteps  | 914071   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0165   |\n",
            "|    n_updates        | 203517   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.11e+03 |\n",
            "|    ep_rew_mean      | 606      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3684     |\n",
            "|    fps              | 260      |\n",
            "|    time_elapsed     | 3513     |\n",
            "|    total_timesteps  | 915436   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0272   |\n",
            "|    n_updates        | 203858   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.1e+03  |\n",
            "|    ep_rew_mean      | 608      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3688     |\n",
            "|    fps              | 260      |\n",
            "|    time_elapsed     | 3521     |\n",
            "|    total_timesteps  | 917761   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.039    |\n",
            "|    n_updates        | 204440   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.09e+03 |\n",
            "|    ep_rew_mean      | 609      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3692     |\n",
            "|    fps              | 260      |\n",
            "|    time_elapsed     | 3525     |\n",
            "|    total_timesteps  | 918731   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00761  |\n",
            "|    n_updates        | 204682   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.08e+03 |\n",
            "|    ep_rew_mean      | 605      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3696     |\n",
            "|    fps              | 260      |\n",
            "|    time_elapsed     | 3535     |\n",
            "|    total_timesteps  | 921361   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00845  |\n",
            "|    n_updates        | 205340   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.09e+03 |\n",
            "|    ep_rew_mean      | 605      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3700     |\n",
            "|    fps              | 260      |\n",
            "|    time_elapsed     | 3541     |\n",
            "|    total_timesteps  | 923036   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0125   |\n",
            "|    n_updates        | 205758   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=925000, episode_reward=426.00 +/- 158.57\n",
            "Episode length: 4529.00 +/- 763.22\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 4.53e+03 |\n",
            "|    mean_reward      | 426      |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 925000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00656  |\n",
            "|    n_updates        | 206249   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.08e+03 |\n",
            "|    ep_rew_mean      | 600      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3704     |\n",
            "|    fps              | 259      |\n",
            "|    time_elapsed     | 3561     |\n",
            "|    total_timesteps  | 925046   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0247   |\n",
            "|    n_updates        | 206261   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.06e+03 |\n",
            "|    ep_rew_mean      | 597      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3708     |\n",
            "|    fps              | 259      |\n",
            "|    time_elapsed     | 3570     |\n",
            "|    total_timesteps  | 927591   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0159   |\n",
            "|    n_updates        | 206897   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.05e+03 |\n",
            "|    ep_rew_mean      | 602      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3712     |\n",
            "|    fps              | 259      |\n",
            "|    time_elapsed     | 3578     |\n",
            "|    total_timesteps  | 929559   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0282   |\n",
            "|    n_updates        | 207389   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.04e+03 |\n",
            "|    ep_rew_mean      | 600      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3716     |\n",
            "|    fps              | 259      |\n",
            "|    time_elapsed     | 3586     |\n",
            "|    total_timesteps  | 931539   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0226   |\n",
            "|    n_updates        | 207884   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.06e+03 |\n",
            "|    ep_rew_mean      | 604      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3720     |\n",
            "|    fps              | 259      |\n",
            "|    time_elapsed     | 3594     |\n",
            "|    total_timesteps  | 933707   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0401   |\n",
            "|    n_updates        | 208426   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.02e+03 |\n",
            "|    ep_rew_mean      | 603      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3724     |\n",
            "|    fps              | 259      |\n",
            "|    time_elapsed     | 3604     |\n",
            "|    total_timesteps  | 936381   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0573   |\n",
            "|    n_updates        | 209095   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.05e+03 |\n",
            "|    ep_rew_mean      | 607      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3728     |\n",
            "|    fps              | 259      |\n",
            "|    time_elapsed     | 3614     |\n",
            "|    total_timesteps  | 939016   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0148   |\n",
            "|    n_updates        | 209753   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.04e+03 |\n",
            "|    ep_rew_mean      | 607      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3732     |\n",
            "|    fps              | 259      |\n",
            "|    time_elapsed     | 3620     |\n",
            "|    total_timesteps  | 940658   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0158   |\n",
            "|    n_updates        | 210164   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.04e+03 |\n",
            "|    ep_rew_mean      | 604      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3736     |\n",
            "|    fps              | 259      |\n",
            "|    time_elapsed     | 3624     |\n",
            "|    total_timesteps  | 941881   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0141   |\n",
            "|    n_updates        | 210470   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.99e+03 |\n",
            "|    ep_rew_mean      | 596      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3740     |\n",
            "|    fps              | 259      |\n",
            "|    time_elapsed     | 3631     |\n",
            "|    total_timesteps  | 943712   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0169   |\n",
            "|    n_updates        | 210927   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4e+03    |\n",
            "|    ep_rew_mean      | 598      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3744     |\n",
            "|    fps              | 259      |\n",
            "|    time_elapsed     | 3638     |\n",
            "|    total_timesteps  | 945420   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0418   |\n",
            "|    n_updates        | 211354   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.01e+03 |\n",
            "|    ep_rew_mean      | 594      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3748     |\n",
            "|    fps              | 259      |\n",
            "|    time_elapsed     | 3642     |\n",
            "|    total_timesteps  | 946636   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0138   |\n",
            "|    n_updates        | 211658   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.02e+03 |\n",
            "|    ep_rew_mean      | 599      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3752     |\n",
            "|    fps              | 259      |\n",
            "|    time_elapsed     | 3650     |\n",
            "|    total_timesteps  | 948760   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00943  |\n",
            "|    n_updates        | 212189   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=950000, episode_reward=879.00 +/- 561.56\n",
            "Episode length: 5071.80 +/- 1960.44\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 5.07e+03 |\n",
            "|    mean_reward      | 879      |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 950000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0299   |\n",
            "|    n_updates        | 212499   |\n",
            "----------------------------------\n",
            "New best mean reward!\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.02e+03 |\n",
            "|    ep_rew_mean      | 601      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3756     |\n",
            "|    fps              | 258      |\n",
            "|    time_elapsed     | 3669     |\n",
            "|    total_timesteps  | 950298   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0152   |\n",
            "|    n_updates        | 212574   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.01e+03 |\n",
            "|    ep_rew_mean      | 599      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3760     |\n",
            "|    fps              | 258      |\n",
            "|    time_elapsed     | 3671     |\n",
            "|    total_timesteps  | 950928   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00955  |\n",
            "|    n_updates        | 212731   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.97e+03 |\n",
            "|    ep_rew_mean      | 595      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3764     |\n",
            "|    fps              | 258      |\n",
            "|    time_elapsed     | 3676     |\n",
            "|    total_timesteps  | 952173   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0348   |\n",
            "|    n_updates        | 213043   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.97e+03 |\n",
            "|    ep_rew_mean      | 596      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3768     |\n",
            "|    fps              | 258      |\n",
            "|    time_elapsed     | 3681     |\n",
            "|    total_timesteps  | 953363   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0637   |\n",
            "|    n_updates        | 213340   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.98e+03 |\n",
            "|    ep_rew_mean      | 599      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3772     |\n",
            "|    fps              | 259      |\n",
            "|    time_elapsed     | 3687     |\n",
            "|    total_timesteps  | 955222   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0205   |\n",
            "|    n_updates        | 213805   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.96e+03 |\n",
            "|    ep_rew_mean      | 599      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3776     |\n",
            "|    fps              | 259      |\n",
            "|    time_elapsed     | 3697     |\n",
            "|    total_timesteps  | 957787   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0169   |\n",
            "|    n_updates        | 214446   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.96e+03 |\n",
            "|    ep_rew_mean      | 598      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3780     |\n",
            "|    fps              | 259      |\n",
            "|    time_elapsed     | 3703     |\n",
            "|    total_timesteps  | 959466   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0162   |\n",
            "|    n_updates        | 214866   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.05e+03 |\n",
            "|    ep_rew_mean      | 610      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3784     |\n",
            "|    fps              | 259      |\n",
            "|    time_elapsed     | 3713     |\n",
            "|    total_timesteps  | 962199   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.011    |\n",
            "|    n_updates        | 215549   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.04e+03 |\n",
            "|    ep_rew_mean      | 609      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3788     |\n",
            "|    fps              | 259      |\n",
            "|    time_elapsed     | 3717     |\n",
            "|    total_timesteps  | 963141   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00928  |\n",
            "|    n_updates        | 215785   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.03e+03 |\n",
            "|    ep_rew_mean      | 609      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3792     |\n",
            "|    fps              | 259      |\n",
            "|    time_elapsed     | 3726     |\n",
            "|    total_timesteps  | 965542   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0226   |\n",
            "|    n_updates        | 216385   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.03e+03 |\n",
            "|    ep_rew_mean      | 611      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3796     |\n",
            "|    fps              | 259      |\n",
            "|    time_elapsed     | 3731     |\n",
            "|    total_timesteps  | 966868   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00855  |\n",
            "|    n_updates        | 216716   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.03e+03 |\n",
            "|    ep_rew_mean      | 611      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3800     |\n",
            "|    fps              | 259      |\n",
            "|    time_elapsed     | 3735     |\n",
            "|    total_timesteps  | 968074   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0173   |\n",
            "|    n_updates        | 217018   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.03e+03 |\n",
            "|    ep_rew_mean      | 611      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3804     |\n",
            "|    fps              | 259      |\n",
            "|    time_elapsed     | 3741     |\n",
            "|    total_timesteps  | 969650   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0116   |\n",
            "|    n_updates        | 217412   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.03e+03 |\n",
            "|    ep_rew_mean      | 612      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3808     |\n",
            "|    fps              | 259      |\n",
            "|    time_elapsed     | 3745     |\n",
            "|    total_timesteps  | 970623   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00956  |\n",
            "|    n_updates        | 217655   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.04e+03 |\n",
            "|    ep_rew_mean      | 609      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3812     |\n",
            "|    fps              | 259      |\n",
            "|    time_elapsed     | 3750     |\n",
            "|    total_timesteps  | 972128   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0135   |\n",
            "|    n_updates        | 218031   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.04e+03 |\n",
            "|    ep_rew_mean      | 610      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3816     |\n",
            "|    fps              | 259      |\n",
            "|    time_elapsed     | 3756     |\n",
            "|    total_timesteps  | 973472   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0293   |\n",
            "|    n_updates        | 218367   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=975000, episode_reward=430.00 +/- 180.19\n",
            "Episode length: 2969.40 +/- 638.75\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 2.97e+03 |\n",
            "|    mean_reward      | 430      |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 975000   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0719   |\n",
            "|    n_updates        | 218749   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.06e+03 |\n",
            "|    ep_rew_mean      | 608      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3820     |\n",
            "|    fps              | 258      |\n",
            "|    time_elapsed     | 3770     |\n",
            "|    total_timesteps  | 975374   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0211   |\n",
            "|    n_updates        | 218843   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.03e+03 |\n",
            "|    ep_rew_mean      | 605      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3824     |\n",
            "|    fps              | 258      |\n",
            "|    time_elapsed     | 3776     |\n",
            "|    total_timesteps  | 976866   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0283   |\n",
            "|    n_updates        | 219216   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4e+03    |\n",
            "|    ep_rew_mean      | 600      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3828     |\n",
            "|    fps              | 258      |\n",
            "|    time_elapsed     | 3780     |\n",
            "|    total_timesteps  | 977878   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0305   |\n",
            "|    n_updates        | 219469   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.03e+03 |\n",
            "|    ep_rew_mean      | 607      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3832     |\n",
            "|    fps              | 258      |\n",
            "|    time_elapsed     | 3787     |\n",
            "|    total_timesteps  | 979866   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0161   |\n",
            "|    n_updates        | 219966   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.03e+03 |\n",
            "|    ep_rew_mean      | 604      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3836     |\n",
            "|    fps              | 258      |\n",
            "|    time_elapsed     | 3792     |\n",
            "|    total_timesteps  | 981283   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00917  |\n",
            "|    n_updates        | 220320   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.01e+03 |\n",
            "|    ep_rew_mean      | 605      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3840     |\n",
            "|    fps              | 258      |\n",
            "|    time_elapsed     | 3801     |\n",
            "|    total_timesteps  | 983888   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0247   |\n",
            "|    n_updates        | 220971   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.03e+03 |\n",
            "|    ep_rew_mean      | 607      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3844     |\n",
            "|    fps              | 258      |\n",
            "|    time_elapsed     | 3807     |\n",
            "|    total_timesteps  | 985300   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.03     |\n",
            "|    n_updates        | 221324   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.03e+03 |\n",
            "|    ep_rew_mean      | 609      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3848     |\n",
            "|    fps              | 258      |\n",
            "|    time_elapsed     | 3815     |\n",
            "|    total_timesteps  | 987488   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0152   |\n",
            "|    n_updates        | 221871   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4e+03    |\n",
            "|    ep_rew_mean      | 603      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3852     |\n",
            "|    fps              | 258      |\n",
            "|    time_elapsed     | 3821     |\n",
            "|    total_timesteps  | 989221   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0317   |\n",
            "|    n_updates        | 222305   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.99e+03 |\n",
            "|    ep_rew_mean      | 604      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3856     |\n",
            "|    fps              | 258      |\n",
            "|    time_elapsed     | 3828     |\n",
            "|    total_timesteps  | 991081   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0184   |\n",
            "|    n_updates        | 222770   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 3.99e+03 |\n",
            "|    ep_rew_mean      | 605      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3860     |\n",
            "|    fps              | 258      |\n",
            "|    time_elapsed     | 3833     |\n",
            "|    total_timesteps  | 992439   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0126   |\n",
            "|    n_updates        | 223109   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.02e+03 |\n",
            "|    ep_rew_mean      | 605      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3864     |\n",
            "|    fps              | 258      |\n",
            "|    time_elapsed     | 3848     |\n",
            "|    total_timesteps  | 996547   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.015    |\n",
            "|    n_updates        | 224136   |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 4.03e+03 |\n",
            "|    ep_rew_mean      | 608      |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3868     |\n",
            "|    fps              | 258      |\n",
            "|    time_elapsed     | 3858     |\n",
            "|    total_timesteps  | 999259   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.01     |\n",
            "|    n_updates        | 224814   |\n",
            "----------------------------------\n",
            "Eval num_timesteps=1000000, episode_reward=414.00 +/- 94.31\n",
            "Episode length: 3167.60 +/- 385.54\n",
            "----------------------------------\n",
            "| eval/               |          |\n",
            "|    mean_ep_length   | 3.17e+03 |\n",
            "|    mean_reward      | 414      |\n",
            "| rollout/            |          |\n",
            "|    exploration_rate | 0.01     |\n",
            "| time/               |          |\n",
            "|    total_timesteps  | 1000000  |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0141   |\n",
            "|    n_updates        | 224999   |\n",
            "----------------------------------\n",
            "Saving to logs//dqn/SpaceInvadersNoFrameskip-v4_3\n"
          ]
        }
      ],
      "source": [
        "!python -m rl_zoo3.train --algo dqn --env SpaceInvadersNoFrameskip-v4  -f logs/  -c dqn.yml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeChoX-3SZfP"
      },
      "source": [
        "#### Solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuocgdokSab9"
      },
      "outputs": [],
      "source": [
        "!python -m rl_zoo3.train --algo dqn  --env SpaceInvadersNoFrameskip-v4 -f logs/ -c dqn.yml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dLomIiMKQaf"
      },
      "source": [
        "## Let's evaluate our agent üëÄ\n",
        "- RL-Baselines3-Zoo provides `enjoy.py`, a python script to evaluate our agent. In most RL libraries, we call the evaluation script `enjoy.py`.\n",
        "- Let's evaluate it for 5000 timesteps üî•"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "co5um_KeKbBJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3749625a-78a7-4ec9-c487-7ddb37d1142a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-09-15 11:27:38.881177: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1757935658.901261   27261 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1757935658.907298   27261 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1757935658.922451   27261 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757935658.922478   27261 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757935658.922482   27261 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757935658.922487   27261 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-09-15 11:27:38.927047: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
            "Loading latest experiment, id=3\n",
            "Loading logs/dqn/SpaceInvadersNoFrameskip-v4_3/SpaceInvadersNoFrameskip-v4.zip\n",
            "A.L.E: Arcade Learning Environment (version 0.11.2+ecc1138)\n",
            "[Powered by Stella]\n",
            "Stacking 4 frames\n",
            "Atari Episode Score: 475.00\n",
            "Atari Episode Length 4101\n",
            "Atari Episode Score: 680.00\n",
            "Atari Episode Length 3521\n",
            "Atari Episode Score: 455.00\n",
            "Atari Episode Length 3487\n",
            "Atari Episode Score: 440.00\n",
            "Atari Episode Length 2455\n",
            "Atari Episode Score: 340.00\n",
            "Atari Episode Length 3493\n"
          ]
        }
      ],
      "source": [
        "!python -m rl_zoo3.enjoy  --algo dqn  --env SpaceInvadersNoFrameskip-v4  --no-render  --n-timesteps 5000  --folder logs/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q24K1tyWSj7t"
      },
      "source": [
        "#### Solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_uSmwGRSk0z"
      },
      "outputs": [],
      "source": [
        "!python -m rl_zoo3.enjoy  --algo dqn  --env SpaceInvadersNoFrameskip-v4  --no-render  --n-timesteps 5000  --folder logs/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liBeTltiHJtr"
      },
      "source": [
        "## Publish our trained model on the Hub üöÄ\n",
        "Now that we saw we got good results after the training, we can publish our trained model on the hub ü§ó with one line of code.\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit3/space-invaders-model.gif\" alt=\"Space Invaders model\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezbHS1q3HYVV"
      },
      "source": [
        "By using `rl_zoo3.push_to_hub` **you evaluate, record a replay, generate a model card of your agent and push it to the hub**.\n",
        "\n",
        "This way:\n",
        "- You can **showcase our work** üî•\n",
        "- You can **visualize your agent playing** üëÄ\n",
        "- You can **share with the community an agent that others can use** üíæ\n",
        "- You can **access a leaderboard üèÜ to see how well your agent is performing compared to your classmates** üëâ  https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMSeZRBiHk6X"
      },
      "source": [
        "To be able to share your model with the community there are three more steps to follow:\n",
        "\n",
        "1Ô∏è‚É£ (If it's not already done) create an account to HF ‚û° https://huggingface.co/join\n",
        "\n",
        "2Ô∏è‚É£ Sign in and then, you need to store your authentication token from the Hugging Face website.\n",
        "- Create a new token (https://huggingface.co/settings/tokens) **with write role**\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/create-token.jpg\" alt=\"Create HF Token\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9O6FI0F8HnzE"
      },
      "source": [
        "- Copy the token\n",
        "- Run the cell below and past the token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Ppu9yePwHrZX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "76c22694e8b64e35b06462a97640a44e",
            "8c90ec6a2ef54bdc9bca1d7df47e39b0",
            "1ef8bbe9cfe64b9abc90ae3fce144d43",
            "bbd7616551034edd9e55914afc853b58",
            "aa1a4f6bdb4d42609ea1f2706caeabf8",
            "48d7e241bd444264a92e983e6d340e4e",
            "6a98e2dfe98f40a083d2c155e07eef5d",
            "6480291582124fb29e30c37163286632",
            "b3e3cc3dd1c6432a95689ac70d8ba86a",
            "acec8b0c7ea54436ab5030e2c6a76a15",
            "840905f790d748d7b1c05c8186caebae",
            "de93a81ca28b413cbbdf7044fbef3c74",
            "64d173ef97044691a493c8e9d5b1abde",
            "49cfa6921b80400799e869ad6d4909a5",
            "c5a9826f0fda4d9cb8c668c6031f9069",
            "6a3c075ec3b84b348038b34ab67710d3",
            "8177e6abb1af4392b938ff54e691e067",
            "7499843ab4694b4fbff2ccb58553c7a3",
            "62b7557321394065ade3ba99dc446bc0",
            "8036d78a7c534ef4a7dada2df7f488af"
          ]
        },
        "outputId": "33db9517-d29e-4ffd-cf57-1b2975cf821b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv‚Ä¶"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "76c22694e8b64e35b06462a97640a44e"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login # To log to our Hugging Face account to be able to upload models to the Hub.\n",
        "notebook_login()\n",
        "!git config --global credential.helper store"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RVEdunPHs8B"
      },
      "source": [
        "If you don't want to use a Google Colab or a Jupyter Notebook, you need to use this command instead: `huggingface-cli login`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSLwdmvhHvjw"
      },
      "source": [
        "3Ô∏è‚É£ We're now ready to push our trained agent to the ü§ó Hub üî•"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PW436XnhHw1H"
      },
      "source": [
        "Let's run push_to_hub.py file to upload our trained agent to the Hub.\n",
        "\n",
        "`--repo-name `: The name of the repo\n",
        "\n",
        "`-orga`: Your Hugging Face username\n",
        "\n",
        "`-f`: Where the trained model folder is (in our case `logs`)\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/notebooks/unit3/select-id.png\" alt=\"Select Id\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Ygk2sEktTDEw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7e550d0-fcc1-4dac-a01a-f77b39495860"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-09-15 11:42:08.338528: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1757936528.359747   30840 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1757936528.365889   30840 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1757936528.381552   30840 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757936528.381579   30840 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757936528.381583   30840 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757936528.381588   30840 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-09-15 11:42:08.386362: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
            "Loading latest experiment, id=3\n",
            "Loading logs/dqn/SpaceInvadersNoFrameskip-v4_3/SpaceInvadersNoFrameskip-v4.zip\n",
            "A.L.E: Arcade Learning Environment (version 0.11.2+ecc1138)\n",
            "[Powered by Stella]\n",
            "Stacking 4 frames\n",
            "Wrapping the env in a VecTransposeImage.\n",
            "Uploading to ShuchengLi/dqn-SpaceInvadersNoFrameskip-v4, make sure to have the rights\n",
            "\u001b[38;5;4m‚Ñπ This function will save, evaluate, generate a video of your agent,\n",
            "create a model card and push everything to the hub. It might take up to some\n",
            "minutes if video generation is activated. This is a work in progress: if you\n",
            "encounter a bug, please open an issue.\u001b[0m\n",
            "Fetching 1 files:   0% 0/1 [00:00<?, ?it/s]\n",
            ".gitattributes: 1.52kB [00:00, 3.01MB/s]\n",
            "Fetching 1 files: 100% 1/1 [00:00<00:00,  2.07it/s]\n",
            "Saving model to: hub/dqn-SpaceInvadersNoFrameskip-v4/dqn-SpaceInvadersNoFrameskip-v4\n",
            "Saving video to /tmp/tmpjvnrsig5/-step-0-to-step-1000.mp4\n",
            "/usr/local/lib/python3.12/dist-packages/moviepy/config_defaults.py:47: SyntaxWarning: invalid escape sequence '\\P'\n",
            "  IMAGEMAGICK_BINARY = r\"C:\\Program Files\\ImageMagick-6.8.8-Q16\\magick.exe\"\n",
            "Moviepy - Building video /tmp/tmpjvnrsig5/-step-0-to-step-1000.mp4.\n",
            "Moviepy - Writing video /tmp/tmpjvnrsig5/-step-0-to-step-1000.mp4\n",
            "\n",
            "Moviepy - Done !\n",
            "Moviepy - video ready /tmp/tmpjvnrsig5/-step-0-to-step-1000.mp4\n",
            "\u001b[38;5;1m‚úò 'DummyVecEnv' object has no attribute 'video_recorder'\u001b[0m\n",
            "\u001b[38;5;1m‚úò We are unable to generate a replay of your agent, the package_to_hub\n",
            "process continues\u001b[0m\n",
            "\u001b[38;5;1m‚úò Please open an issue at\n",
            "https://github.com/huggingface/huggingface_sb3/issues\u001b[0m\n",
            "\u001b[38;5;4m‚Ñπ Pushing repo dqn-SpaceInvadersNoFrameskip-v4 to the Hugging Face\n",
            "Hub\u001b[0m\n",
            "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            \n",
            "New Data Upload                         : |          |  0.00B /  0.00B            \u001b[A\n",
            "\n",
            "  ...oFrameskip-v4/pytorch_variables.pth: 100% 1.26k/1.26k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "Processing Files (1 / 1)                :   0% 1.26k/54.3M [00:00<4:57:44, 3.04kB/s, 6.31kB/s  ]\n",
            "\n",
            "\n",
            "  ...NoFrameskip-v4/policy.optimizer.pth:   2% 205k/13.5M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "  ...ceInvadersNoFrameskip-v4/policy.pth:   2% 205k/13.5M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ...dqn-SpaceInvadersNoFrameskip-v4.zip:   2% 413k/27.2M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ...Frameskip-v4/train_eval_metrics.zip:   2% 555/36.6k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "  ...oFrameskip-v4/pytorch_variables.pth: 100% 1.26k/1.26k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  ...NoFrameskip-v4/policy.optimizer.pth:   2% 205k/13.5M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "  ...ceInvadersNoFrameskip-v4/policy.pth:   2% 205k/13.5M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ...dqn-SpaceInvadersNoFrameskip-v4.zip:   2% 413k/27.2M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (1 / 5)                :   2% 825k/54.3M [00:00<00:31, 1.68MB/s, 2.07MB/s  ]   \n",
            "New Data Upload                         :   2% 806k/53.1M [00:00<00:39, 1.31MB/s, 2.02MB/s  ]\u001b[A\n",
            "\n",
            "  ...oFrameskip-v4/pytorch_variables.pth: 100% 1.26k/1.26k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  ...NoFrameskip-v4/policy.optimizer.pth:   6% 820k/13.5M [00:00<00:04, 3.07MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "  ...ceInvadersNoFrameskip-v4/policy.pth:   6% 820k/13.5M [00:00<00:04, 3.07MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ...dqn-SpaceInvadersNoFrameskip-v4.zip:   6% 1.65M/27.2M [00:00<00:04, 6.19MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (1 / 5)                :   6% 3.30M/54.3M [00:00<00:09, 5.61MB/s, 5.50MB/s  ]\n",
            "New Data Upload                         :   6% 3.22M/53.1M [00:00<00:10, 4.73MB/s, 5.38MB/s  ]\u001b[A\n",
            "\n",
            "  ...oFrameskip-v4/pytorch_variables.pth: 100% 1.26k/1.26k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  ...NoFrameskip-v4/policy.optimizer.pth:  18% 2.46M/13.5M [00:00<00:01, 5.64MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "  ...ceInvadersNoFrameskip-v4/policy.pth:  18% 2.46M/13.5M [00:00<00:01, 5.64MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ...dqn-SpaceInvadersNoFrameskip-v4.zip:  18% 4.96M/27.2M [00:00<00:01, 11.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (1 / 5)                :  18% 9.89M/54.3M [00:01<00:02, 15.0MB/s, 12.4MB/s  ]\n",
            "New Data Upload                         :  18% 9.67M/53.1M [00:01<00:03, 13.3MB/s, 12.1MB/s  ]\u001b[A\n",
            "\n",
            "  ...oFrameskip-v4/pytorch_variables.pth: 100% 1.26k/1.26k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  ...NoFrameskip-v4/policy.optimizer.pth:  46% 6.15M/13.5M [00:00<00:00, 9.91MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "  ...ceInvadersNoFrameskip-v4/policy.pth:  46% 6.15M/13.5M [00:00<00:00, 9.91MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ...dqn-SpaceInvadersNoFrameskip-v4.zip:  46% 12.4M/27.2M [00:00<00:00, 20.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (1 / 5)                :  46% 24.7M/54.3M [00:01<00:00, 34.6MB/s, 24.7MB/s  ]\n",
            "New Data Upload                         :  46% 24.2M/53.1M [00:01<00:00, 31.6MB/s, 24.2MB/s  ]\u001b[A\n",
            "\n",
            "  ...oFrameskip-v4/pytorch_variables.pth: 100% 1.26k/1.26k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  ...NoFrameskip-v4/policy.optimizer.pth:  71% 9.64M/13.5M [00:00<00:00, 11.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "  ...ceInvadersNoFrameskip-v4/policy.pth:  71% 9.63M/13.5M [00:00<00:00, 11.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ...dqn-SpaceInvadersNoFrameskip-v4.zip:  71% 19.4M/27.2M [00:00<00:00, 23.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (1 / 5)                :  71% 38.7M/54.3M [00:01<00:00, 45.9MB/s, 32.3MB/s  ]\n",
            "New Data Upload                         :  71% 37.9M/53.1M [00:01<00:00, 42.8MB/s, 31.6MB/s  ]\u001b[A\n",
            "\n",
            "  ...oFrameskip-v4/pytorch_variables.pth: 100% 1.26k/1.26k [00:01<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  ...NoFrameskip-v4/policy.optimizer.pth:  99% 13.3M/13.5M [00:01<00:00, 13.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "  ...ceInvadersNoFrameskip-v4/policy.pth:  99% 13.3M/13.5M [00:01<00:00, 13.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ...dqn-SpaceInvadersNoFrameskip-v4.zip:  99% 26.9M/27.2M [00:01<00:00, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (1 / 5)                :  99% 53.5M/54.3M [00:01<00:00, 54.7MB/s, 38.2MB/s  ]\n",
            "New Data Upload                         :  99% 52.4M/53.1M [00:01<00:00, 51.9MB/s, 37.4MB/s  ]\u001b[A\n",
            "\n",
            "  ...oFrameskip-v4/pytorch_variables.pth: 100% 1.26k/1.26k [00:01<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  ...NoFrameskip-v4/policy.optimizer.pth:  99% 13.3M/13.5M [00:01<00:00, 10.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "  ...ceInvadersNoFrameskip-v4/policy.pth:  99% 13.3M/13.5M [00:01<00:00, 10.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ...dqn-SpaceInvadersNoFrameskip-v4.zip:  99% 26.9M/27.2M [00:01<00:00, 22.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ...Frameskip-v4/train_eval_metrics.zip:  99% 36.1k/36.6k [00:01<00:00, 29.6kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "  ...oFrameskip-v4/pytorch_variables.pth: 100% 1.26k/1.26k [00:01<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  ...NoFrameskip-v4/policy.optimizer.pth:  99% 13.3M/13.5M [00:01<00:00, 9.37MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "  ...ceInvadersNoFrameskip-v4/policy.pth:  99% 13.3M/13.5M [00:01<00:00, 9.37MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ...dqn-SpaceInvadersNoFrameskip-v4.zip:  99% 26.9M/27.2M [00:01<00:00, 18.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ...Frameskip-v4/train_eval_metrics.zip:  99% 36.1k/36.6k [00:01<00:00, 25.4kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "  ...oFrameskip-v4/pytorch_variables.pth: 100% 1.26k/1.26k [00:01<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  ...NoFrameskip-v4/policy.optimizer.pth: 100% 13.5M/13.5M [00:01<00:00, 8.31MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "  ...ceInvadersNoFrameskip-v4/policy.pth: 100% 13.5M/13.5M [00:01<00:00, 8.31MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ...dqn-SpaceInvadersNoFrameskip-v4.zip: 100% 27.2M/27.2M [00:01<00:00, 16.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 5)                : 100% 54.3M/54.3M [00:02<00:00, 24.0MB/s, 27.1MB/s  ]\n",
            "New Data Upload                         : 100% 53.1M/53.1M [00:02<00:00, 23.2MB/s, 26.6MB/s  ]\u001b[A\n",
            "\n",
            "  ...oFrameskip-v4/pytorch_variables.pth: 100% 1.26k/1.26k [00:01<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  ...NoFrameskip-v4/policy.optimizer.pth: 100% 13.5M/13.5M [00:01<00:00, 7.87MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "  ...ceInvadersNoFrameskip-v4/policy.pth: 100% 13.5M/13.5M [00:01<00:00, 7.87MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ...dqn-SpaceInvadersNoFrameskip-v4.zip: 100% 27.2M/27.2M [00:01<00:00, 15.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ...Frameskip-v4/train_eval_metrics.zip: 100% 36.6k/36.6k [00:01<00:00, 21.3kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "  ...oFrameskip-v4/pytorch_variables.pth: 100% 1.26k/1.26k [00:01<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  ...NoFrameskip-v4/policy.optimizer.pth: 100% 13.5M/13.5M [00:01<00:00, 7.39MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "  ...ceInvadersNoFrameskip-v4/policy.pth: 100% 13.5M/13.5M [00:01<00:00, 7.39MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ...dqn-SpaceInvadersNoFrameskip-v4.zip: 100% 27.2M/27.2M [00:01<00:00, 14.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 5)                : 100% 54.3M/54.3M [00:02<00:00, 22.5MB/s, 24.7MB/s  ]\n",
            "New Data Upload                         : 100% 53.1M/53.1M [00:02<00:00, 22.0MB/s, 24.2MB/s  ]\n",
            "  ...oFrameskip-v4/pytorch_variables.pth: 100% 1.26k/1.26k [00:01<?, ?B/s]\n",
            "  ...NoFrameskip-v4/policy.optimizer.pth: 100% 13.5M/13.5M [00:01<00:00, 7.39MB/s]\n",
            "  ...ceInvadersNoFrameskip-v4/policy.pth: 100% 13.5M/13.5M [00:01<00:00, 7.39MB/s]\n",
            "  ...dqn-SpaceInvadersNoFrameskip-v4.zip: 100% 27.2M/27.2M [00:01<00:00, 14.9MB/s]\n",
            "  ...Frameskip-v4/train_eval_metrics.zip: 100% 36.6k/36.6k [00:01<00:00, 20.0kB/s]\n",
            "\u001b[38;5;4m‚Ñπ Your model is pushed to the hub. You can view your model here:\n",
            "https://huggingface.co/ShuchengLi/dqn-SpaceInvadersNoFrameskip-v4\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python -m rl_zoo3.push_to_hub  --algo dqn  --env SpaceInvadersNoFrameskip-v4  --repo-name dqn-SpaceInvadersNoFrameskip-v4 -orga ShuchengLi -f logs/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otgpa0rhS9wR"
      },
      "source": [
        "#### Solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HQNlAXuEhci"
      },
      "outputs": [],
      "source": [
        "!python -m rl_zoo3.push_to_hub  --algo dqn  --env SpaceInvadersNoFrameskip-v4  --repo-name dqn-SpaceInvadersNoFrameskip-v4  -orga ThomasSimonini  -f logs/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0D4F5zsTTJ-L"
      },
      "source": [
        "###."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff89kd2HL1_s"
      },
      "source": [
        "Congrats ü•≥ you've just trained and uploaded your first Deep Q-Learning agent using RL-Baselines-3 Zoo. The script above should have displayed a link to a model repository such as https://huggingface.co/ThomasSimonini/dqn-SpaceInvadersNoFrameskip-v4. When you go to this link, you can:\n",
        "\n",
        "- See a **video preview of your agent** at the right.\n",
        "- Click \"Files and versions\" to see all the files in the repository.\n",
        "- Click \"Use in stable-baselines3\" to get a code snippet that shows how to load the model.\n",
        "- A model card (`README.md` file) which gives a description of the model and the hyperparameters you used.\n",
        "\n",
        "Under the hood, the Hub uses git-based repositories (don't worry if you don't know what git is), which means you can update the model with new versions as you experiment and improve your agent.\n",
        "\n",
        "**Compare the results of your agents with your classmates** using the [leaderboard](https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard) üèÜ"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Personal Challenge: Continue training the model you published\n",
        "\n",
        "Retrieve the model from HF, configure the agent environment and train it.\n",
        "\n",
        "‰ΩÜËøô‰∏™Ê≤°ÊàêÂäü„ÄÇNameNotFound error. Ëøô‰∏™ÁéØÂ¢ÉË≤å‰ºº‰∏çËÉΩÈÄöËøágymÁõ¥Êé•ÂàõÈÄ†„ÄÇ"
      ],
      "metadata": {
        "id": "XFpkKRkRfwBK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_sb3 import load_from_hub\n",
        "from stable_baselines3 import DQN\n",
        "import gymnasium as gym\n",
        "\n",
        "repo_id = \"ShuchengLi/dqn-SpaceInvadersNoFrameskip-v4\"\n",
        "filename = \"dqn-SpaceInvadersNoFrameskip-v4.zip\"   # ËøôÊòØpush_to_hub‰∏ä‰º†ÁöÑÊ®°ÂûãÊñá‰ª∂Âêç\n",
        "\n",
        "checkpoint_path = load_from_hub(repo_id=repo_id, filename=filename)\n",
        "model = DQN.load(checkpoint_path)\n",
        "\n",
        "# env = model.get_env() ## This return None since the model on HF has no env config stored\n",
        "env = gym.make('SpaceInvadersNoFrameskip-v4')\n",
        "model.set_env(env)\n",
        "model.learn(total_timesteps=10000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "tmGx3-w5fzhC",
        "outputId": "d03f9232-19d1-408a-f66c-93543d18f6df"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameNotFound",
          "evalue": "Environment `SpaceInvadersNoFrameskip` doesn't exist.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameNotFound\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3919491120.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# env = model.get_env() ## This return None since the model on HF has no env config stored\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SpaceInvadersNoFrameskip-v4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gymnasium/envs/registration.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(id, max_episode_steps, disable_env_checker, **kwargs)\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0;31m# The environment name can include an unloaded module in \"module:env_name\" style\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m         \u001b[0menv_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_find_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEnvSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gymnasium/envs/registration.py\u001b[0m in \u001b[0;36m_find_spec\u001b[0;34m(env_id)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0menv_spec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0m_check_version_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         raise error.Error(\n\u001b[1;32m    528\u001b[0m             \u001b[0;34mf\"No registered env with id: {env_name}. Did you register it, or import the package that registers it? Use `gymnasium.pprint_registry()` to see all of the registered environments.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gymnasium/envs/registration.py\u001b[0m in \u001b[0;36m_check_version_exists\u001b[0;34m(ns, name, version)\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m     \u001b[0m_check_name_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gymnasium/envs/registration.py\u001b[0m in \u001b[0;36m_check_name_exists\u001b[0;34m(ns, name)\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0msuggestion_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\" Did you mean: `{suggestion[0]}`?\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msuggestion\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m     raise error.NameNotFound(\n\u001b[0m\u001b[1;32m    370\u001b[0m         \u001b[0;34mf\"Environment `{name}` doesn't exist{namespace_msg}.{suggestion_msg}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     )\n",
            "\u001b[0;31mNameNotFound\u001b[0m: Environment `SpaceInvadersNoFrameskip` doesn't exist."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyRKcCYY-dIo"
      },
      "source": [
        "## Load a powerful trained model üî•\n",
        "- The Stable-Baselines3 team uploaded **more than 150 trained Deep Reinforcement Learning agents on the Hub**.\n",
        "\n",
        "You can find them here: üëâ https://huggingface.co/sb3\n",
        "\n",
        "Some examples:\n",
        "- Asteroids: https://huggingface.co/sb3/dqn-AsteroidsNoFrameskip-v4\n",
        "- Beam Rider: https://huggingface.co/sb3/dqn-BeamRiderNoFrameskip-v4\n",
        "- Breakout: https://huggingface.co/sb3/dqn-BreakoutNoFrameskip-v4\n",
        "- Road Runner: https://huggingface.co/sb3/dqn-RoadRunnerNoFrameskip-v4\n",
        "\n",
        "Let's load an agent playing Beam Rider: https://huggingface.co/sb3/dqn-BeamRiderNoFrameskip-v4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "B-9QVFIROI5Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "0b3badf7-ea79-4b9e-f942-1b98abab1da8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<video controls autoplay><source src=\"https://huggingface.co/sb3/dqn-BeamRiderNoFrameskip-v4/resolve/main/replay.mp4\" type=\"video/mp4\"></video>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "%%html\n",
        "<video controls autoplay><source src=\"https://huggingface.co/sb3/dqn-BeamRiderNoFrameskip-v4/resolve/main/replay.mp4\" type=\"video/mp4\"></video>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZQNY_r6NJtC"
      },
      "source": [
        "1. We download the model using `rl_zoo3.load_from_hub`, and place it in a new folder that we can call `rl_trained`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "OdBNZHy0NGTR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6cd5526-ed19-4f02-fccc-a72cafbc5a6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-09-15 13:06:12.059948: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1757941572.080248   51734 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1757941572.086495   51734 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1757941572.102329   51734 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757941572.102362   51734 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757941572.102366   51734 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757941572.102372   51734 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-09-15 13:06:12.107336: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
            "Downloading from https://huggingface.co/sb3/dqn-BeamRiderNoFrameskip-v4\n",
            "dqn-BeamRiderNoFrameskip-v4.zip: 100% 27.2M/27.2M [00:00<00:00, 36.6MB/s]\n",
            "config.yml: 100% 548/548 [00:00<00:00, 4.14MB/s]\n",
            "No normalization file\n",
            "args.yml: 100% 887/887 [00:00<00:00, 6.46MB/s]\n",
            "env_kwargs.yml: 100% 3.00/3.00 [00:00<00:00, 25.5kB/s]\n",
            "train_eval_metrics.zip: 100% 244k/244k [00:00<00:00, 100MB/s]\n",
            "Saving to rl_trained/dqn/BeamRiderNoFrameskip-v4_1\n"
          ]
        }
      ],
      "source": [
        "# Download model and save it into the logs/ folder\n",
        "!python -m rl_zoo3.load_from_hub --algo dqn --env BeamRiderNoFrameskip-v4 -orga sb3 -f rl_trained/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFt6hmWsNdBo"
      },
      "source": [
        "2. Let's evaluate if for 5000 timesteps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "aOxs0rNuN0uS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07d775a8-f853-4c21-89de-4133cd1348b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-09-15 13:06:27.964820: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1757941587.985075   51810 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1757941587.991079   51810 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1757941588.006577   51810 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757941588.006606   51810 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757941588.006612   51810 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1757941588.006616   51810 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-09-15 13:06:28.011238: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
            "Loading latest experiment, id=1\n",
            "Loading rl_trained/dqn/BeamRiderNoFrameskip-v4_1/BeamRiderNoFrameskip-v4.zip\n",
            "A.L.E: Arcade Learning Environment (version 0.11.2+ecc1138)\n",
            "[Powered by Stella]\n",
            "Stacking 4 frames\n",
            "/usr/local/lib/python3.12/dist-packages/stable_baselines3/common/save_util.py:167: UserWarning: Could not deserialize object exploration_schedule. Consider using `custom_objects` argument to replace this object.\n",
            "Exception: code expected at least 16 arguments, got 15\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:95: UserWarning: You loaded a model that was trained using OpenAI Gym. We strongly recommend transitioning to Gymnasium by saving that model again.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/stable_baselines3/common/base_class.py:773: UserWarning: You are probably loading a DQN model saved with SB3 < 2.4.0, we truncated the optimizer state so you can save the model again to avoid issues in the future (see https://github.com/DLR-RM/stable-baselines3/pull/1963 for more info). Original error: loaded state dict contains a parameter group that doesn't match the size of optimizer's group \n",
            "Note: the model should still work fine, this only a warning.\n",
            "  warnings.warn(\n",
            "Atari Episode Score: 3028.00\n",
            "Atari Episode Length 14816\n"
          ]
        }
      ],
      "source": [
        "!python -m rl_zoo3.enjoy --algo dqn --env BeamRiderNoFrameskip-v4 -n 5000  -f rl_trained/ --no-render"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxMDuDfPON57"
      },
      "source": [
        "Why not trying to train your own **Deep Q-Learning Agent playing BeamRiderNoFrameskip-v4? üèÜ.**\n",
        "\n",
        "If you want to try, check https://huggingface.co/sb3/dqn-BeamRiderNoFrameskip-v4#hyperparameters **in the model card, you have the hyperparameters of the trained agent.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xL_ZtUgpOuY6"
      },
      "source": [
        "But finding hyperparameters can be a daunting task. Fortunately, we'll see in the next Unit, how we can **use Optuna for optimizing the Hyperparameters üî•.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pqaco8W-huW"
      },
      "source": [
        "## Some additional challenges üèÜ\n",
        "The best way to learn **is to try things by your own**!\n",
        "\n",
        "In the [Leaderboard](https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard) you will find your agents. Can you get to the top?\n",
        "\n",
        "Here's a list of environments you can try to train your agent with:\n",
        "- BeamRiderNoFrameskip-v4\n",
        "- BreakoutNoFrameskip-v4\n",
        "- EnduroNoFrameskip-v4\n",
        "- PongNoFrameskip-v4\n",
        "\n",
        "Also, **if you want to learn to implement Deep Q-Learning by yourself**, you definitely should look at CleanRL implementation: https://github.com/vwxyzjn/cleanrl/blob/master/cleanrl/dqn_atari.py\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit4/atari-envs.gif\" alt=\"Environments\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paS-XKo4-kmu"
      },
      "source": [
        "________________________________________________________________________\n",
        "Congrats on finishing this chapter!\n",
        "\n",
        "If you‚Äôre still feel confused with all these elements...it's totally normal! **This was the same for me and for all people who studied RL.**\n",
        "\n",
        "Take time to really **grasp the material before continuing and try the additional challenges**. It‚Äôs important to master these elements and having a solid foundations.\n",
        "\n",
        "In the next unit, **we‚Äôre going to learn about [Optuna](https://optuna.org/)**. One of the most critical task in Deep Reinforcement Learning is to find a good set of training hyperparameters. And Optuna is a library that helps you to automate the search.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WRx7tO7-mvC"
      },
      "source": [
        "\n",
        "\n",
        "### This is a course built with you üë∑üèø‚Äç‚ôÄÔ∏è\n",
        "\n",
        "Finally, we want to improve and update the course iteratively with your feedback. If you have some, please fill this form üëâ https://forms.gle/3HgA7bEHwAmmLfwh9\n",
        "\n",
        "We're constantly trying to improve our tutorials, so **if you find some issues in this notebook**, please [open an issue on the Github Repo](https://github.com/huggingface/deep-rl-class/issues)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "See you on Bonus unit 2! üî•"
      ],
      "metadata": {
        "id": "Kc3udPT-RcXc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fS3Xerx0fIMV"
      },
      "source": [
        "### Keep Learning, Stay Awesome ü§ó"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "SeChoX-3SZfP"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "76c22694e8b64e35b06462a97640a44e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_6a98e2dfe98f40a083d2c155e07eef5d"
          }
        },
        "8c90ec6a2ef54bdc9bca1d7df47e39b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6480291582124fb29e30c37163286632",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_b3e3cc3dd1c6432a95689ac70d8ba86a",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "1ef8bbe9cfe64b9abc90ae3fce144d43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_acec8b0c7ea54436ab5030e2c6a76a15",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_840905f790d748d7b1c05c8186caebae",
            "value": ""
          }
        },
        "bbd7616551034edd9e55914afc853b58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_de93a81ca28b413cbbdf7044fbef3c74",
            "style": "IPY_MODEL_64d173ef97044691a493c8e9d5b1abde",
            "value": true
          }
        },
        "aa1a4f6bdb4d42609ea1f2706caeabf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_49cfa6921b80400799e869ad6d4909a5",
            "style": "IPY_MODEL_c5a9826f0fda4d9cb8c668c6031f9069",
            "tooltip": ""
          }
        },
        "48d7e241bd444264a92e983e6d340e4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a3c075ec3b84b348038b34ab67710d3",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8177e6abb1af4392b938ff54e691e067",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "6a98e2dfe98f40a083d2c155e07eef5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "6480291582124fb29e30c37163286632": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3e3cc3dd1c6432a95689ac70d8ba86a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "acec8b0c7ea54436ab5030e2c6a76a15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "840905f790d748d7b1c05c8186caebae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de93a81ca28b413cbbdf7044fbef3c74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64d173ef97044691a493c8e9d5b1abde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49cfa6921b80400799e869ad6d4909a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5a9826f0fda4d9cb8c668c6031f9069": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "6a3c075ec3b84b348038b34ab67710d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8177e6abb1af4392b938ff54e691e067": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7499843ab4694b4fbff2ccb58553c7a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62b7557321394065ade3ba99dc446bc0",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8036d78a7c534ef4a7dada2df7f488af",
            "value": "Connecting..."
          }
        },
        "62b7557321394065ade3ba99dc446bc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8036d78a7c534ef4a7dada2df7f488af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}