{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMWCxryliChXZEr+RoUFOTg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CaptainAmu/Reinforcement-Learning-Tutorial/blob/main/notebooks/unit1/unit1_try.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dependencies & Install packages"
      ],
      "metadata": {
        "id": "iEmC5sAqQSaU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J88PD-0ZHwHR"
      },
      "outputs": [],
      "source": [
        "%%html\n",
        "<video controls autoplay><source src=\"https://huggingface.co/sb3/ppo-LunarLander-v2/resolve/main/replay.mp4\" type=\"video/mp4\"></video>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install swig cmake"
      ],
      "metadata": {
        "id": "lT9k2drDI7vJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt"
      ],
      "metadata": {
        "id": "d3dV4nmfJOc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use some of the newest version of packages\n",
        "\n",
        "!pip install pygame==2.5.2 -q # -q quiet install\n",
        "!pip install box2d-py==2.3.5 -q\n",
        "!pip install gymnasium>=1.0.0 -q\n",
        "!pip install stable-baselines3==2.0.0a5 -q\n",
        "!pip install huggingface_sb3 -q"
      ],
      "metadata": {
        "id": "lw5f6ru8IjDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get install -y python3-opengl\n",
        "!apt install ffmpeg\n",
        "!apt install xvfb\n",
        "!pip3 install pyvirtualdisplay"
      ],
      "metadata": {
        "id": "QmwNJda1JsrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```pygame==2.5.2```\n",
        "\n",
        "一个游戏开发框架，RL 里常用来渲染环境画面（比如 LunarLander 的小飞船动起来）。在 gymnasium[box2d] 里是必需的。\n",
        "\n",
        "```box2d-py==2.3.5```\n",
        "\n",
        "Box2D 是一个 2D 物理引擎，用来模拟重力、碰撞等。LunarLander-v2 就是基于 Box2D 实现的。\n",
        "\n",
        "```gymnasium```\n",
        "\n",
        "强化学习的标准环境库（OpenAI Gym 的继承版本）。提供各种环境：LunarLander-v2、CartPole-v1、Atari 等。\n",
        "\n",
        "```stable-baselines3==2.0.0a5```\n",
        "\n",
        "常用的深度强化学习算法库（PPO、DQN、A2C 等）。你训练智能体时用的核心库。\n",
        "\n",
        "```huggingface_sb3```\n",
        "\n",
        "Hugging Face 提供的扩展包，方便把训练好的 RL 模型上传/下载到 Hugging Face Hub。类似“模型仓库管理工具”。[链接文字](https://)"
      ],
      "metadata": {
        "id": "2sWJ4_vMSqrg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Import Packages"
      ],
      "metadata": {
        "id": "JO3ZZ5aEQPDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Virtual display\n",
        "from pyvirtualdisplay import Display\n",
        "\n",
        "virtual_display = Display(visible=0, size=(1400, 900))\n",
        "virtual_display.start()"
      ],
      "metadata": {
        "id": "p0V9V0oEKPdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium\n",
        "print(f'Using Gymnasium version {gymnasium.__version__}')\n",
        "\n",
        "from huggingface_sb3 import load_from_hub, package_to_hub\n",
        "from huggingface_hub import notebook_login # To log to our Hugging Face account to be able to upload models to the Hub.\n",
        "\n",
        "from stable_baselines3 import PPO, DQN\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.monitor import Monitor"
      ],
      "metadata": {
        "id": "tb5LsCP-KT3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "gagaga try"
      ],
      "metadata": {
        "id": "IZlmG-kxLMAh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Random policy"
      ],
      "metadata": {
        "id": "JgQ_dL2zQd8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "\n",
        "# Create environment and initial observation\n",
        "env = gym.make(\"LunarLander-v2\")\n",
        "observation, info = env.reset()\n",
        "\n",
        "# Sample actions and update environment\n",
        "for _ in range(20):\n",
        "  action = env.action_space.sample()\n",
        "  print(f'Action taken: {action}')\n",
        "  observation, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "  if terminated or truncated:\n",
        "    print(\"Environment is reset!\")\n",
        "    observation, info = env.reset()\n",
        "\n",
        "env.close()"
      ],
      "metadata": {
        "id": "2tw1kNX0QkHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Investigate the environment"
      ],
      "metadata": {
        "id": "H76dfSPtoU4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make(\"LunarLander-v2\")\n",
        "print(f'Action space, {env.action_space}')\n",
        "print(f'Action space sample: {env.action_space.sample()}')\n",
        "print(f'Observation space, {env.observation_space}')\n",
        "print(f'Observation space sample: {env.observation_space.sample()}')"
      ],
      "metadata": {
        "id": "o71f1SLZoXB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The observation space (8 entries) describes the\n",
        "* x-coord,\n",
        "* y-coord,\n",
        "* x-velocity,\n",
        "* y-velocity,\n",
        "* angle,\n",
        "* angular-velocity,\n",
        "* left_leg_on_ground,\n",
        "* right_leg_on_ground."
      ],
      "metadata": {
        "id": "FmH94hnvpHR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = make_vec_env(\"LunarLander-v2\", n_envs = 16) # 16 envs in parallel"
      ],
      "metadata": {
        "id": "HMi7vpmFpSqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a Model"
      ],
      "metadata": {
        "id": "P9XzgpgXqVYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PPO Model\n",
        "model_PPO = PPO(\n",
        "    policy = 'MlpPolicy',\n",
        "    env = env,\n",
        "    n_steps = 1024,\n",
        "    batch_size = 64,\n",
        "    n_epochs = 4,\n",
        "    gamma = 0.999,\n",
        "    gae_lambda = 0.98,\n",
        "    ent_coef = 0.01,\n",
        "    verbose = 1\n",
        ")\n",
        "\n",
        "# DQN Model\n",
        "model_DQN = DQN(\n",
        "    policy = 'MlpPolicy',\n",
        "    env = env,\n",
        "    batch_size = 64,\n",
        "    gamma = 0.999,\n",
        "    learning_rate = 0.00025\n",
        "    )"
      ],
      "metadata": {
        "id": "u5LtuHG5qWYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training a agent\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XkxTZWjqqsey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_PPO.learn(total_timesteps = 100000)\n",
        "model_PPO.save(\"PPO-Lunarlander-v2\")"
      ],
      "metadata": {
        "id": "HlCka4zIqti-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_DQN.learn(total_timesteps = 100000)\n",
        "model_DQN.save(\"DQN-Lunarlander-v2\")"
      ],
      "metadata": {
        "id": "Y5XTbA0vtTTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate an agent"
      ],
      "metadata": {
        "id": "9clRCvxKryiO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(agent):\n",
        "  '''Evaluate the performance of a trained agent in LunarLander-v2'''\n",
        "  eval_env = Monitor(gym.make(\"LunarLander-v2\", render_mode = 'rgb_array'))\n",
        "  mean_reward, std_reward = evaluate_policy(agent, eval_env, n_eval_episodes = 10, deterministic = True)\n",
        "  print(f'Mean reward={mean_reward}+-{std_reward}')\n",
        "  pass\n",
        "\n",
        "evaluate(model_DQN)"
      ],
      "metadata": {
        "id": "1LiQ_kqAr2pX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pushing a model to the Hugging Face Hub\n",
        "### 1. Create repo (with access token) and login to it."
      ],
      "metadata": {
        "id": "x5nFv02buq58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "notebook_login()\n",
        "!git config --global credential.helper store"
      ],
      "metadata": {
        "id": "I8UM1yrruuSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "\n",
        "hf_token = userdata.get('HF_TOKEN')  # 从 secret 中读取\n",
        "login(hf_token)"
      ],
      "metadata": {
        "id": "PRIGCr0QHcOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Push model to Hub"
      ],
      "metadata": {
        "id": "rnxPUT9xzsV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from huggingface_sb3 import package_to_hub"
      ],
      "metadata": {
        "id": "JHJaqgPuyrmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model_DQN\n",
        "repo_id = 'ShuchengLi/dqn-LunarLander-v2'\n",
        "model_name = 'dqn-LunarLander-v2'\n",
        "env_id = 'LunarLander-v2'\n",
        "model_architecture = 'DQN'\n",
        "commit_message = 'Upload DQN LunarLander-v2 trained agent'\n",
        "eval_env = DummyVecEnv([lambda: Monitor(gym.make(env_id, render_mode = 'rgb_array'))])\n",
        "\n",
        "package_to_hub(model=model,\n",
        "               model_name=model_name,\n",
        "               model_architecture=model_architecture,\n",
        "               env_id=env_id,\n",
        "               eval_env=eval_env,\n",
        "               repo_id=repo_id,\n",
        "               commit_message=commit_message)"
      ],
      "metadata": {
        "id": "fCY31G_xxWG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading a model from HuggingFace & Evaluating"
      ],
      "metadata": {
        "id": "zBHNvHuf-qSA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shimmy  # shimmy API conversion tool to convert Gym to compatible with Gymnasium usage."
      ],
      "metadata": {
        "id": "Iucp4qrDAbLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_sb3 import load_from_hub\n",
        "from stable_baselines3 import DQN\n",
        "repo_id = 'ShuchengLi/dqn-LunarLander-v2'\n",
        "filename = 'dqn-LunarLander-v2.zip'\n",
        "\n",
        "custom_objects = {\n",
        "            \"learning_rate\": 0.0,\n",
        "            \"lr_schedule\": lambda _: 0.0,\n",
        "            \"clip_range\": lambda _: 0.0,\n",
        "}\n",
        "\n",
        "checkpoint = load_from_hub(repo_id, filename)\n",
        "model_loaded = DQN.load(checkpoint, custom_objects=custom_objects, print_system_info=True)"
      ],
      "metadata": {
        "id": "6Dnjch8E-sG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_env = Monitor(gym.make(\"LunarLander-v2\", render_mode = 'rgb_array'))\n",
        "mean_reward, std_reward = evaluate_policy(model_loaded, eval_env, n_eval_episodes = 10, deterministic = True)\n",
        "print(f\"Mean reward={mean_reward:.2f} +/- {std_reward:.2f}\")"
      ],
      "metadata": {
        "id": "xs_iAbHUB4NQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}